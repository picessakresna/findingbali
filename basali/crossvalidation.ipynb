{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## About This Project"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "This project is focused on the detection of 'Aksara Bali' - a traditional Balinese script. The goal is to develop a machine learning model that can accurately identify different characters in the Aksara Bali script.\n",
        "\n",
        "The project involves several steps, including data collection, data preprocessing, model training, and model evaluation. The data consists of images of different Aksara Bali characters, which are stored in separate directories for each character.\n",
        "\n",
        "The model is built using TensorFlow, a popular machine learning library. It uses a Convolutional Neural Network (CNN), which is a type of deep learning model particularly effective for image classification tasks.\n",
        "\n",
        "The model's performance is evaluated based on its accuracy in predicting the correct Aksara Bali character from the images in the validation set. Various strategies, such as regularization and learning rate adjustment, are employed to optimize the model's performance and prevent overfitting.\n",
        "\n",
        "The project is a significant contribution to the preservation and digitization of traditional scripts, enabling more efficient and accurate recognition of Aksara Bali characters."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preparation Files for Making Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "For prepare this project you can download the dataset from https://drive.google.com/drive/folders/1STj-TVq42OYVbbtfBHML00313Y0TKFTU?usp=drive_link"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Preparation Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "eDCMjoNNeC4A"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import shutil\n",
        "import random\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3E_2rhFNeUOE",
        "outputId": "697b6d51-18fd-4ad5-9196-70073eccc7df"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "D:\\SELF\\ML\\aksara-detection\\code\\findingbali\\dataset\n"
          ]
        }
      ],
      "source": [
        "%cd D:/SELF/ML/aksara-detection/code/findingbali/dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDwdsKdaemwG",
        "outputId": "297c96f0-f25a-44a0-9b6b-e179569a6c0a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "There are 99 images of adeg-adeg\n",
            "There are 93 images of ba\n",
            "There are 101 images of bisah\n",
            "There are 98 images of ca\n",
            "There are 97 images of cecek\n",
            "There are 95 images of da\n",
            "There are 95 images of delapan\n",
            "There are 91 images of dua\n",
            "There are 96 images of empat\n",
            "There are 101 images of enam\n",
            "There are 98 images of ga\n",
            "There are 76 images of gantungan ba\n",
            "There are 79 images of gantungan ca\n",
            "There are 71 images of gantungan da\n",
            "There are 73 images of gantungan ga\n",
            "There are 78 images of gantungan ha\n",
            "There are 72 images of gantungan ja\n",
            "There are 79 images of gantungan ka\n",
            "There are 75 images of gantungan la\n",
            "There are 75 images of gantungan ma\n",
            "There are 76 images of gantungan na\n",
            "There are 77 images of gantungan nga\n",
            "There are 72 images of gantungan nya\n",
            "There are 77 images of gantungan pa\n",
            "There are 75 images of gantungan ra\n",
            "There are 81 images of gantungan sa\n",
            "There are 77 images of gantungan ta\n",
            "There are 73 images of gantungan wa\n",
            "There are 74 images of gantungan ya\n",
            "There are 96 images of ha\n",
            "There are 108 images of ja\n",
            "There are 104 images of ka\n",
            "There are 98 images of la\n",
            "There are 100 images of lima\n",
            "There are 101 images of ma\n",
            "There are 109 images of na\n",
            "There are 101 images of nga\n",
            "There are 95 images of nya\n",
            "There are 99 images of pa\n",
            "There are 98 images of pepet\n",
            "There are 94 images of ra\n",
            "There are 97 images of sa\n",
            "There are 98 images of satu\n",
            "There are 100 images of sembilan\n",
            "There are 97 images of suku\n",
            "There are 101 images of surang\n",
            "There are 94 images of ta\n",
            "There are 101 images of taleng\n",
            "There are 102 images of taleng tedong\n",
            "There are 100 images of tedong\n",
            "There are 101 images of tiga\n",
            "There are 101 images of tujuh\n",
            "There are 99 images of ulu\n",
            "There are 100 images of wa\n",
            "There are 95 images of ya\n"
          ]
        }
      ],
      "source": [
        "list_aksara = {\n",
        "    0: 'adeg-adeg',\n",
        "    1: 'ba',\n",
        "    2: 'bisah',\n",
        "    3: 'ca',\n",
        "    4: 'cecek',\n",
        "    5: 'da',\n",
        "    6: 'delapan',\n",
        "    7: 'dua',\n",
        "    8: 'empat',\n",
        "    9: 'enam',\n",
        "    10: 'ga',\n",
        "    11: 'gantungan ba',\n",
        "    12: 'gantungan ca',\n",
        "    13: 'gantungan da',\n",
        "    14: 'gantungan ga',\n",
        "    15: 'gantungan ha',\n",
        "    16: 'gantungan ja',\n",
        "    17: 'gantungan ka',\n",
        "    18: 'gantungan la',\n",
        "    19: 'gantungan ma',\n",
        "    20: 'gantungan na',\n",
        "    21: 'gantungan nga',\n",
        "    22: 'gantungan nya',\n",
        "    23: 'gantungan pa',\n",
        "    24: 'gantungan ra',\n",
        "    25: 'gantungan sa',\n",
        "    26: 'gantungan ta',\n",
        "    27: 'gantungan wa',\n",
        "    28: 'gantungan ya',\n",
        "    29: 'ha',\n",
        "    30: 'ja',\n",
        "    31: 'ka',\n",
        "    32: 'la',\n",
        "    33: 'lima',\n",
        "    34: 'ma',\n",
        "    35: 'na',\n",
        "    36: 'nga',\n",
        "    37: 'nya',\n",
        "    38: 'pa',\n",
        "    39: 'pepet',\n",
        "    40: 'ra',\n",
        "    41: 'sa',\n",
        "    42: 'satu',\n",
        "    43: 'sembilan',\n",
        "    44: 'suku',\n",
        "    45: 'surang',\n",
        "    46: 'ta',\n",
        "    47: 'taleng',\n",
        "    48: 'taleng tedong',\n",
        "    49: 'tedong',\n",
        "    50: 'tiga',\n",
        "    51: 'tujuh',\n",
        "    52: 'ulu',\n",
        "    53: 'wa',\n",
        "    54: 'ya'\n",
        "}\n",
        "\n",
        "list_aksara_array = np.array(list(list_aksara.values()))\n",
        "\n",
        "for key, value in list_aksara.items():\n",
        "    source_path = f\"D:/SELF/ML/aksara-detection/code/findingbali/dataset/{value}\"\n",
        "    if not os.path.exists(source_path):\n",
        "        os.makedirs(source_path)\n",
        "    print(f\"There are {len(os.listdir(source_path))} images of {value}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 3987 images belonging to 55 classes.\n",
            "Found 1026 images belonging to 55 classes.\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 2s 652ms/step - loss: 4.0082 - accuracy: 0.0222 - val_loss: 4.0094 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.9994 - accuracy: 0.0667 - val_loss: 4.0244 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.9803 - accuracy: 0.0222 - val_loss: 4.0518 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 3.9400 - accuracy: 0.0667 - val_loss: 4.0789 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.8873 - accuracy: 0.0222 - val_loss: 4.1134 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.8364 - accuracy: 0.0222 - val_loss: 4.1685 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 3.7421 - accuracy: 0.0444 - val_loss: 4.3272 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 3.9317 - accuracy: 0.0444 - val_loss: 4.3540 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.9914 - accuracy: 0.0222 - val_loss: 4.2136 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.7982 - accuracy: 0.0667 - val_loss: 4.1210 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.7886 - accuracy: 0.0222 - val_loss: 4.1063 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.8162 - accuracy: 0.0000e+00 - val_loss: 4.1310 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.8333 - accuracy: 0.0444 - val_loss: 4.1762 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.7895 - accuracy: 0.1333 - val_loss: 4.2245 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.6725 - accuracy: 0.1111 - val_loss: 4.2823 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.6619 - accuracy: 0.1111 - val_loss: 4.3469 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.7603 - accuracy: 0.0222 - val_loss: 4.3754 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.6071 - accuracy: 0.0667 - val_loss: 4.3656 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 3.5811 - accuracy: 0.0667 - val_loss: 4.3705 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 3.6866 - accuracy: 0.1111 - val_loss: 4.4118 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.5639 - accuracy: 0.0444 - val_loss: 4.4309 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.6669 - accuracy: 0.1333 - val_loss: 4.3414 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.5604 - accuracy: 0.0889 - val_loss: 4.2786 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 3.6013 - accuracy: 0.0667 - val_loss: 4.2455 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 3.6265 - accuracy: 0.0667 - val_loss: 4.2797 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 3.6565 - accuracy: 0.0222 - val_loss: 4.3134 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.4826 - accuracy: 0.0444 - val_loss: 4.3949 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.5010 - accuracy: 0.1111 - val_loss: 4.4898 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 3.4894 - accuracy: 0.0889 - val_loss: 4.5512 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.4418 - accuracy: 0.1333 - val_loss: 4.5952 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.3797 - accuracy: 0.0444 - val_loss: 4.6635 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.4366 - accuracy: 0.0222 - val_loss: 4.6505 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 3.4565 - accuracy: 0.0889 - val_loss: 4.6765 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 3.1499 - accuracy: 0.2000 - val_loss: 4.9237 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.1327 - accuracy: 0.1111 - val_loss: 4.8470 - val_accuracy: 0.1667\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 3.0913 - accuracy: 0.2000 - val_loss: 4.7910 - val_accuracy: 0.1667\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.2393 - accuracy: 0.1333 - val_loss: 4.8061 - val_accuracy: 0.1667\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 2.9732 - accuracy: 0.2444 - val_loss: 5.1325 - val_accuracy: 0.1667\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 2.8124 - accuracy: 0.2889 - val_loss: 5.2004 - val_accuracy: 0.1667\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 2.6003 - accuracy: 0.3111 - val_loss: 5.0406 - val_accuracy: 0.1667\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 2.5920 - accuracy: 0.3333 - val_loss: 5.0516 - val_accuracy: 0.1667\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 2.3558 - accuracy: 0.3333 - val_loss: 5.2414 - val_accuracy: 0.0833\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 2.0353 - accuracy: 0.4000 - val_loss: 5.6196 - val_accuracy: 0.0833\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 1.8642 - accuracy: 0.4000 - val_loss: 6.0571 - val_accuracy: 0.0833\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 1.6668 - accuracy: 0.4667 - val_loss: 6.2637 - val_accuracy: 0.0833\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 1.6107 - accuracy: 0.5556 - val_loss: 6.3904 - val_accuracy: 0.0833\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 1.6788 - accuracy: 0.5333 - val_loss: 6.5039 - val_accuracy: 0.0833\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 1.4920 - accuracy: 0.6000 - val_loss: 6.7941 - val_accuracy: 0.0833\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.9061 - accuracy: 0.7111 - val_loss: 7.4345 - val_accuracy: 0.0833\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 1.4325 - accuracy: 0.6222 - val_loss: 7.8213 - val_accuracy: 0.1667\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 1.0850 - accuracy: 0.6667 - val_loss: 8.1074 - val_accuracy: 0.1667\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 1.0511 - accuracy: 0.7111 - val_loss: 8.4642 - val_accuracy: 0.0833\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.8786 - accuracy: 0.7556 - val_loss: 8.7681 - val_accuracy: 0.0833\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.7697 - accuracy: 0.7778 - val_loss: 8.5873 - val_accuracy: 0.0833\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.8593 - accuracy: 0.7333 - val_loss: 8.2800 - val_accuracy: 0.1667\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.8228 - accuracy: 0.7111 - val_loss: 8.1795 - val_accuracy: 0.1667\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.5946 - accuracy: 0.8000 - val_loss: 8.3852 - val_accuracy: 0.1667\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.6870 - accuracy: 0.8000 - val_loss: 8.3965 - val_accuracy: 0.2500\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.5019 - accuracy: 0.8667 - val_loss: 8.6770 - val_accuracy: 0.2500\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.6348 - accuracy: 0.8444 - val_loss: 8.7350 - val_accuracy: 0.2500\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.3876 - accuracy: 0.8222 - val_loss: 8.9436 - val_accuracy: 0.2500\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.5642 - accuracy: 0.8667 - val_loss: 9.2509 - val_accuracy: 0.2500\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.4588 - accuracy: 0.8000 - val_loss: 9.4455 - val_accuracy: 0.2500\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.4037 - accuracy: 0.8222 - val_loss: 9.6984 - val_accuracy: 0.2500\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.5902 - accuracy: 0.8000 - val_loss: 9.9391 - val_accuracy: 0.2500\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.4294 - accuracy: 0.8444 - val_loss: 10.0836 - val_accuracy: 0.2500\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.3200 - accuracy: 0.9111 - val_loss: 9.9988 - val_accuracy: 0.2500\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.3541 - accuracy: 0.8667 - val_loss: 9.8037 - val_accuracy: 0.2500\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.5046 - accuracy: 0.8444 - val_loss: 9.2741 - val_accuracy: 0.2500\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.4411 - accuracy: 0.8667 - val_loss: 8.6200 - val_accuracy: 0.2500\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.4629 - accuracy: 0.9333 - val_loss: 8.2807 - val_accuracy: 0.2500\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.7065 - accuracy: 0.8222 - val_loss: 7.9452 - val_accuracy: 0.1667\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.4145 - accuracy: 0.8444 - val_loss: 7.8647 - val_accuracy: 0.1667\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.3983 - accuracy: 0.9111 - val_loss: 8.1035 - val_accuracy: 0.1667\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.5329 - accuracy: 0.8222 - val_loss: 8.4418 - val_accuracy: 0.1667\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.3920 - accuracy: 0.8889 - val_loss: 8.7008 - val_accuracy: 0.1667\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.2298 - accuracy: 0.9333 - val_loss: 8.9023 - val_accuracy: 0.1667\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.2889 - accuracy: 0.9111 - val_loss: 9.2549 - val_accuracy: 0.2500\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.1728 - accuracy: 0.9111 - val_loss: 9.6631 - val_accuracy: 0.2500\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.3389 - accuracy: 0.8889 - val_loss: 9.8120 - val_accuracy: 0.2500\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.2323 - accuracy: 0.9556 - val_loss: 9.8422 - val_accuracy: 0.2500\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.5034 - accuracy: 0.8667 - val_loss: 9.9020 - val_accuracy: 0.2500\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.1252 - accuracy: 0.9556 - val_loss: 10.1000 - val_accuracy: 0.2500\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.2137 - accuracy: 0.9111 - val_loss: 10.3578 - val_accuracy: 0.2500\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.4217 - accuracy: 0.8667 - val_loss: 10.4577 - val_accuracy: 0.2500\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.5696 - accuracy: 0.8000 - val_loss: 10.4059 - val_accuracy: 0.2500\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.1919 - accuracy: 0.9111 - val_loss: 10.4751 - val_accuracy: 0.2500\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.4718 - accuracy: 0.9111 - val_loss: 10.2047 - val_accuracy: 0.2500\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.2370 - accuracy: 0.8889 - val_loss: 9.8686 - val_accuracy: 0.2500\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.4527 - accuracy: 0.8667 - val_loss: 9.8394 - val_accuracy: 0.2500\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.2950 - accuracy: 0.9333 - val_loss: 10.0008 - val_accuracy: 0.2500\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.2913 - accuracy: 0.9333 - val_loss: 10.0566 - val_accuracy: 0.2500\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.2939 - accuracy: 0.9111 - val_loss: 10.0772 - val_accuracy: 0.2500\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.3341 - accuracy: 0.9111 - val_loss: 10.0478 - val_accuracy: 0.2500\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.2392 - accuracy: 0.9333 - val_loss: 10.1241 - val_accuracy: 0.1667\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.2178 - accuracy: 0.9333 - val_loss: 10.1695 - val_accuracy: 0.1667\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.1429 - accuracy: 0.9333 - val_loss: 10.3805 - val_accuracy: 0.1667\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.2422 - accuracy: 0.9111 - val_loss: 10.5790 - val_accuracy: 0.1667\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.1332 - accuracy: 0.9556 - val_loss: 10.7291 - val_accuracy: 0.2500\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.3066 - accuracy: 0.9111 - val_loss: 10.8963 - val_accuracy: 0.2500\n",
            "Score for fold 1: loss of 14.09227466583252; accuracy of 0.0%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 1s 153ms/step - loss: 4.0068 - accuracy: 0.0444 - val_loss: 4.0054 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 4.0053 - accuracy: 0.0222 - val_loss: 4.0017 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.9659 - accuracy: 0.0000e+00 - val_loss: 3.9877 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.8622 - accuracy: 0.0889 - val_loss: 3.9857 - val_accuracy: 0.0833\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.8557 - accuracy: 0.0667 - val_loss: 4.0257 - val_accuracy: 0.0833\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.8455 - accuracy: 0.0000e+00 - val_loss: 4.0204 - val_accuracy: 0.0833\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.9213 - accuracy: 0.0222 - val_loss: 4.0002 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.8446 - accuracy: 0.0444 - val_loss: 3.9988 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.8861 - accuracy: 0.0444 - val_loss: 4.0013 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.8429 - accuracy: 0.0667 - val_loss: 4.0098 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.9066 - accuracy: 0.0444 - val_loss: 4.0287 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 3.7093 - accuracy: 0.0667 - val_loss: 4.0651 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.7711 - accuracy: 0.1111 - val_loss: 4.1342 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.7835 - accuracy: 0.0444 - val_loss: 4.2243 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.9174 - accuracy: 0.0222 - val_loss: 4.2502 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 3.6758 - accuracy: 0.0667 - val_loss: 4.2434 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.7117 - accuracy: 0.1111 - val_loss: 4.2269 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.6805 - accuracy: 0.0889 - val_loss: 4.2140 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 3.6155 - accuracy: 0.0444 - val_loss: 4.2276 - val_accuracy: 0.0833\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.7288 - accuracy: 0.0222 - val_loss: 4.2367 - val_accuracy: 0.0833\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 3.7114 - accuracy: 0.0889 - val_loss: 4.2418 - val_accuracy: 0.0833\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.6386 - accuracy: 0.0444 - val_loss: 4.2310 - val_accuracy: 0.0833\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 3.6409 - accuracy: 0.0889 - val_loss: 4.2390 - val_accuracy: 0.0833\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.5294 - accuracy: 0.0889 - val_loss: 4.2966 - val_accuracy: 0.0833\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.6372 - accuracy: 0.0889 - val_loss: 4.3672 - val_accuracy: 0.0833\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.7874 - accuracy: 0.0444 - val_loss: 4.3886 - val_accuracy: 0.0833\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.7035 - accuracy: 0.0667 - val_loss: 4.3710 - val_accuracy: 0.0833\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.5842 - accuracy: 0.1111 - val_loss: 4.3805 - val_accuracy: 0.0833\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.5377 - accuracy: 0.0667 - val_loss: 4.4311 - val_accuracy: 0.0833\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.7058 - accuracy: 0.0222 - val_loss: 4.4673 - val_accuracy: 0.0833\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.5643 - accuracy: 0.0444 - val_loss: 4.4736 - val_accuracy: 0.0833\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 3.7603 - accuracy: 0.0667 - val_loss: 4.4384 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.5536 - accuracy: 0.0444 - val_loss: 4.3931 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 3.7164 - accuracy: 0.0667 - val_loss: 4.3521 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.7102 - accuracy: 0.0000e+00 - val_loss: 4.3114 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.6371 - accuracy: 0.0222 - val_loss: 4.3164 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.5808 - accuracy: 0.0667 - val_loss: 4.3636 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.5900 - accuracy: 0.0222 - val_loss: 4.4344 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 3.4462 - accuracy: 0.1556 - val_loss: 4.6023 - val_accuracy: 0.0833\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 3.4991 - accuracy: 0.0444 - val_loss: 4.7871 - val_accuracy: 0.0833\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.6362 - accuracy: 0.1111 - val_loss: 4.6821 - val_accuracy: 0.0833\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.4157 - accuracy: 0.0889 - val_loss: 4.5740 - val_accuracy: 0.0833\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.6589 - accuracy: 0.0444 - val_loss: 4.5196 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.5419 - accuracy: 0.0667 - val_loss: 4.5197 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.5484 - accuracy: 0.1111 - val_loss: 4.5574 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.5081 - accuracy: 0.0889 - val_loss: 4.6542 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 3.5361 - accuracy: 0.1333 - val_loss: 4.7025 - val_accuracy: 0.0833\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.5745 - accuracy: 0.0667 - val_loss: 4.6736 - val_accuracy: 0.0833\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.5713 - accuracy: 0.1111 - val_loss: 4.5543 - val_accuracy: 0.0833\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.6086 - accuracy: 0.0444 - val_loss: 4.4886 - val_accuracy: 0.0833\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.6035 - accuracy: 0.0222 - val_loss: 4.4473 - val_accuracy: 0.0833\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.4413 - accuracy: 0.0222 - val_loss: 4.5389 - val_accuracy: 0.0833\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.5651 - accuracy: 0.0222 - val_loss: 4.6863 - val_accuracy: 0.0833\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.6281 - accuracy: 0.0222 - val_loss: 4.6953 - val_accuracy: 0.0833\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.3566 - accuracy: 0.0889 - val_loss: 4.7006 - val_accuracy: 0.0833\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.3946 - accuracy: 0.0889 - val_loss: 5.0523 - val_accuracy: 0.0833\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 3.4531 - accuracy: 0.0889 - val_loss: 5.2575 - val_accuracy: 0.0833\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.4724 - accuracy: 0.1111 - val_loss: 5.1595 - val_accuracy: 0.0833\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.2491 - accuracy: 0.0889 - val_loss: 5.1872 - val_accuracy: 0.0833\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.3894 - accuracy: 0.0889 - val_loss: 5.4052 - val_accuracy: 0.0833\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.1938 - accuracy: 0.1556 - val_loss: 5.3989 - val_accuracy: 0.0833\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 2.9714 - accuracy: 0.1778 - val_loss: 5.2751 - val_accuracy: 0.0833\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 2.9248 - accuracy: 0.1778 - val_loss: 5.6236 - val_accuracy: 0.0833\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 2.7231 - accuracy: 0.2000 - val_loss: 6.2229 - val_accuracy: 0.0833\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 2.6781 - accuracy: 0.2444 - val_loss: 6.4854 - val_accuracy: 0.0833\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 2.5876 - accuracy: 0.3111 - val_loss: 6.7970 - val_accuracy: 0.1667\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 2.3376 - accuracy: 0.4222 - val_loss: 6.9994 - val_accuracy: 0.1667\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 2.5466 - accuracy: 0.4000 - val_loss: 6.8148 - val_accuracy: 0.1667\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 2.0140 - accuracy: 0.4000 - val_loss: 6.8611 - val_accuracy: 0.2500\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 2.1490 - accuracy: 0.3778 - val_loss: 7.2027 - val_accuracy: 0.2500\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 2.1973 - accuracy: 0.2889 - val_loss: 7.5555 - val_accuracy: 0.2500\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 1.7666 - accuracy: 0.4222 - val_loss: 7.5634 - val_accuracy: 0.1667\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 1.3346 - accuracy: 0.6889 - val_loss: 7.8694 - val_accuracy: 0.0833\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 1.2092 - accuracy: 0.6667 - val_loss: 8.5404 - val_accuracy: 0.0833\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 1.1537 - accuracy: 0.6667 - val_loss: 8.7936 - val_accuracy: 0.0833\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 1.2771 - accuracy: 0.7111 - val_loss: 8.6588 - val_accuracy: 0.0833\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 1.0465 - accuracy: 0.6889 - val_loss: 8.5040 - val_accuracy: 0.1667\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 1.0111 - accuracy: 0.7556 - val_loss: 8.9516 - val_accuracy: 0.2500\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.8343 - accuracy: 0.7556 - val_loss: 10.0946 - val_accuracy: 0.1667\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.4122 - accuracy: 0.9111 - val_loss: 11.2011 - val_accuracy: 0.1667\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.8588 - accuracy: 0.8222 - val_loss: 10.9429 - val_accuracy: 0.2500\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 1.2811 - accuracy: 0.6667 - val_loss: 9.0140 - val_accuracy: 0.2500\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.6967 - accuracy: 0.8889 - val_loss: 7.8067 - val_accuracy: 0.2500\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.6218 - accuracy: 0.8444 - val_loss: 7.1647 - val_accuracy: 0.2500\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5981 - accuracy: 0.9111 - val_loss: 6.7802 - val_accuracy: 0.2500\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.6782 - accuracy: 0.8444 - val_loss: 6.9124 - val_accuracy: 0.2500\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.8971 - accuracy: 0.8222 - val_loss: 6.3811 - val_accuracy: 0.2500\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.4023 - accuracy: 0.9111 - val_loss: 6.3280 - val_accuracy: 0.2500\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.4202 - accuracy: 0.8889 - val_loss: 7.0798 - val_accuracy: 0.2500\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.4736 - accuracy: 0.8000 - val_loss: 8.8131 - val_accuracy: 0.2500\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.5278 - accuracy: 0.8222 - val_loss: 9.5298 - val_accuracy: 0.2500\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.5455 - accuracy: 0.8222 - val_loss: 9.4140 - val_accuracy: 0.2500\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.6605 - accuracy: 0.8444 - val_loss: 8.4854 - val_accuracy: 0.2500\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.3692 - accuracy: 0.8889 - val_loss: 7.9938 - val_accuracy: 0.2500\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.2232 - accuracy: 0.9111 - val_loss: 7.8813 - val_accuracy: 0.2500\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.5475 - accuracy: 0.8667 - val_loss: 8.1366 - val_accuracy: 0.2500\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.4720 - accuracy: 0.8222 - val_loss: 8.2725 - val_accuracy: 0.2500\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.5546 - accuracy: 0.8222 - val_loss: 7.9792 - val_accuracy: 0.2500\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.1436 - accuracy: 0.9556 - val_loss: 8.3459 - val_accuracy: 0.2500\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.5289 - accuracy: 0.8222 - val_loss: 8.7417 - val_accuracy: 0.2500\n",
            "Score for fold 2: loss of 9.689757347106934; accuracy of 14.28571492433548%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 1s 154ms/step - loss: 4.0075 - accuracy: 0.0000e+00 - val_loss: 4.0018 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 3.9977 - accuracy: 0.0222 - val_loss: 3.9903 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.9492 - accuracy: 0.0444 - val_loss: 3.9964 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.8875 - accuracy: 0.0222 - val_loss: 4.0566 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 4.0872 - accuracy: 0.0000e+00 - val_loss: 4.0348 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.9151 - accuracy: 0.0444 - val_loss: 4.0109 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.8229 - accuracy: 0.0444 - val_loss: 4.0103 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.8946 - accuracy: 0.0444 - val_loss: 4.0171 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.8739 - accuracy: 0.1111 - val_loss: 4.0245 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.8617 - accuracy: 0.0222 - val_loss: 4.0366 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.7858 - accuracy: 0.0444 - val_loss: 4.0689 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.8460 - accuracy: 0.0000e+00 - val_loss: 4.1226 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.7499 - accuracy: 0.0889 - val_loss: 4.1688 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 3.8230 - accuracy: 0.0667 - val_loss: 4.1923 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 3.6607 - accuracy: 0.0667 - val_loss: 4.2439 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.5629 - accuracy: 0.0889 - val_loss: 4.3369 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.7169 - accuracy: 0.0444 - val_loss: 4.4263 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.7094 - accuracy: 0.0444 - val_loss: 4.3352 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.6803 - accuracy: 0.1111 - val_loss: 4.1969 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.7150 - accuracy: 0.0444 - val_loss: 4.1493 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.6795 - accuracy: 0.0444 - val_loss: 4.1515 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 3.7826 - accuracy: 0.0222 - val_loss: 4.1654 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.6638 - accuracy: 0.1111 - val_loss: 4.1860 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 3.6748 - accuracy: 0.0444 - val_loss: 4.2210 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 3.6536 - accuracy: 0.0444 - val_loss: 4.2669 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.7093 - accuracy: 0.0444 - val_loss: 4.3043 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.7017 - accuracy: 0.0444 - val_loss: 4.2972 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.5806 - accuracy: 0.0000e+00 - val_loss: 4.3031 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.6736 - accuracy: 0.0889 - val_loss: 4.2909 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.6078 - accuracy: 0.0667 - val_loss: 4.2910 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.6268 - accuracy: 0.1111 - val_loss: 4.3182 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.6307 - accuracy: 0.0444 - val_loss: 4.3438 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.4645 - accuracy: 0.1111 - val_loss: 4.5249 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.4545 - accuracy: 0.0889 - val_loss: 4.7915 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 3.6047 - accuracy: 0.0444 - val_loss: 4.6882 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 3.5192 - accuracy: 0.0667 - val_loss: 4.5075 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.3772 - accuracy: 0.0889 - val_loss: 4.4871 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 3.5017 - accuracy: 0.0444 - val_loss: 4.6049 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.5398 - accuracy: 0.0444 - val_loss: 4.7436 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.6027 - accuracy: 0.0222 - val_loss: 4.7597 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.4707 - accuracy: 0.0444 - val_loss: 4.7667 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 3.6359 - accuracy: 0.0222 - val_loss: 4.6555 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.5892 - accuracy: 0.0222 - val_loss: 4.6214 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.5501 - accuracy: 0.0667 - val_loss: 4.7480 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.3888 - accuracy: 0.1333 - val_loss: 5.2970 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.4766 - accuracy: 0.0667 - val_loss: 5.3985 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.4307 - accuracy: 0.1333 - val_loss: 5.0594 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.4333 - accuracy: 0.0667 - val_loss: 5.1823 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.3749 - accuracy: 0.0667 - val_loss: 5.5684 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.3195 - accuracy: 0.0889 - val_loss: 5.9647 - val_accuracy: 0.0000e+00\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.2650 - accuracy: 0.1111 - val_loss: 6.1869 - val_accuracy: 0.0000e+00\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 3.2527 - accuracy: 0.1111 - val_loss: 6.1431 - val_accuracy: 0.0000e+00\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.0262 - accuracy: 0.1556 - val_loss: 6.6743 - val_accuracy: 0.0000e+00\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.0062 - accuracy: 0.1778 - val_loss: 7.2533 - val_accuracy: 0.0000e+00\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 2.8105 - accuracy: 0.2222 - val_loss: 7.5344 - val_accuracy: 0.0000e+00\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 2.8183 - accuracy: 0.2222 - val_loss: 7.9340 - val_accuracy: 0.0000e+00\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 2.5895 - accuracy: 0.3778 - val_loss: 8.4365 - val_accuracy: 0.0000e+00\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 2.4481 - accuracy: 0.2667 - val_loss: 8.0884 - val_accuracy: 0.0000e+00\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 2.3211 - accuracy: 0.2889 - val_loss: 7.8912 - val_accuracy: 0.0000e+00\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 2.0889 - accuracy: 0.3333 - val_loss: 7.8440 - val_accuracy: 0.0000e+00\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 1.8790 - accuracy: 0.4889 - val_loss: 7.8405 - val_accuracy: 0.0000e+00\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 1.7746 - accuracy: 0.4667 - val_loss: 8.4187 - val_accuracy: 0.0000e+00\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 1.3382 - accuracy: 0.6444 - val_loss: 9.7299 - val_accuracy: 0.0833\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 1.6127 - accuracy: 0.4889 - val_loss: 10.8825 - val_accuracy: 0.0833\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 1.4115 - accuracy: 0.5556 - val_loss: 10.8619 - val_accuracy: 0.0000e+00\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 1.1772 - accuracy: 0.6667 - val_loss: 12.1973 - val_accuracy: 0.0000e+00\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 1.0257 - accuracy: 0.7111 - val_loss: 14.6984 - val_accuracy: 0.0000e+00\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.8688 - accuracy: 0.7556 - val_loss: 17.3893 - val_accuracy: 0.0833\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.9858 - accuracy: 0.7556 - val_loss: 18.2934 - val_accuracy: 0.0833\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.7118 - accuracy: 0.8000 - val_loss: 19.3749 - val_accuracy: 0.0833\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.7959 - accuracy: 0.7111 - val_loss: 20.3501 - val_accuracy: 0.0833\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.8668 - accuracy: 0.7111 - val_loss: 19.7333 - val_accuracy: 0.0833\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.5144 - accuracy: 0.8222 - val_loss: 20.0087 - val_accuracy: 0.0833\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.8195 - accuracy: 0.7778 - val_loss: 20.0573 - val_accuracy: 0.0833\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 1.2928 - accuracy: 0.5778 - val_loss: 18.2656 - val_accuracy: 0.0833\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.6841 - accuracy: 0.8000 - val_loss: 16.1595 - val_accuracy: 0.0833\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.5788 - accuracy: 0.8222 - val_loss: 15.3815 - val_accuracy: 0.0833\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.4595 - accuracy: 0.8667 - val_loss: 16.4418 - val_accuracy: 0.0833\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.6948 - accuracy: 0.8000 - val_loss: 17.0758 - val_accuracy: 0.0833\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.2944 - accuracy: 0.9111 - val_loss: 17.7674 - val_accuracy: 0.0833\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.2069 - accuracy: 0.9333 - val_loss: 18.7393 - val_accuracy: 0.0833\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.3082 - accuracy: 0.9333 - val_loss: 20.3196 - val_accuracy: 0.0833\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.2202 - accuracy: 0.8889 - val_loss: 20.3628 - val_accuracy: 0.0833\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.3389 - accuracy: 0.8889 - val_loss: 19.1136 - val_accuracy: 0.0833\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.5280 - accuracy: 0.8222 - val_loss: 18.4768 - val_accuracy: 0.0833\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.5158 - accuracy: 0.8222 - val_loss: 18.6953 - val_accuracy: 0.0833\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.9030 - accuracy: 0.7556 - val_loss: 18.9240 - val_accuracy: 0.0833\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.3369 - accuracy: 0.8889 - val_loss: 19.0189 - val_accuracy: 0.0833\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.3139 - accuracy: 0.9556 - val_loss: 19.9986 - val_accuracy: 0.0833\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.3807 - accuracy: 0.8889 - val_loss: 21.7144 - val_accuracy: 0.0833\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.5207 - accuracy: 0.8444 - val_loss: 22.4615 - val_accuracy: 0.0833\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.3316 - accuracy: 0.9111 - val_loss: 22.8016 - val_accuracy: 0.0833\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.2538 - accuracy: 0.9556 - val_loss: 23.7393 - val_accuracy: 0.0833\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.1531 - accuracy: 0.9333 - val_loss: 24.7527 - val_accuracy: 0.0833\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.1992 - accuracy: 0.9111 - val_loss: 25.8213 - val_accuracy: 0.0833\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.3209 - accuracy: 0.9111 - val_loss: 26.3732 - val_accuracy: 0.0833\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.2266 - accuracy: 0.8889 - val_loss: 26.5449 - val_accuracy: 0.0833\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.4557 - accuracy: 0.8444 - val_loss: 25.2447 - val_accuracy: 0.0833\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.5252 - accuracy: 0.9111 - val_loss: 23.2086 - val_accuracy: 0.0833\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.1628 - accuracy: 0.9556 - val_loss: 21.9748 - val_accuracy: 0.0833\n",
            "Score for fold 3: loss of 15.010416984558105; accuracy of 14.28571492433548%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 1s 152ms/step - loss: 4.0080 - accuracy: 0.0889 - val_loss: 4.0050 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.9950 - accuracy: 0.0000e+00 - val_loss: 4.0160 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.9298 - accuracy: 0.0222 - val_loss: 4.0712 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.9641 - accuracy: 0.0889 - val_loss: 4.0778 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.9074 - accuracy: 0.0000e+00 - val_loss: 4.0789 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 3.8129 - accuracy: 0.0667 - val_loss: 4.1022 - val_accuracy: 0.0833\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 4.0124 - accuracy: 0.0444 - val_loss: 4.0684 - val_accuracy: 0.0833\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.7992 - accuracy: 0.0889 - val_loss: 4.0442 - val_accuracy: 0.0833\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.8231 - accuracy: 0.0222 - val_loss: 4.0494 - val_accuracy: 0.0833\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.8388 - accuracy: 0.0222 - val_loss: 4.0797 - val_accuracy: 0.0833\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.8767 - accuracy: 0.0444 - val_loss: 4.1111 - val_accuracy: 0.0833\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.7788 - accuracy: 0.0000e+00 - val_loss: 4.1489 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.7631 - accuracy: 0.0000e+00 - val_loss: 4.1866 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.6972 - accuracy: 0.0222 - val_loss: 4.2252 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.6089 - accuracy: 0.0667 - val_loss: 4.2414 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.5739 - accuracy: 0.0000e+00 - val_loss: 4.2680 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 3.6838 - accuracy: 0.0444 - val_loss: 4.3078 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 3.8682 - accuracy: 0.0222 - val_loss: 4.2298 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.8766 - accuracy: 0.0222 - val_loss: 4.1413 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.7388 - accuracy: 0.0444 - val_loss: 4.1077 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.7202 - accuracy: 0.0444 - val_loss: 4.1065 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.7498 - accuracy: 0.0222 - val_loss: 4.1293 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.6627 - accuracy: 0.0667 - val_loss: 4.1882 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.6274 - accuracy: 0.0889 - val_loss: 4.2996 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.6922 - accuracy: 0.0444 - val_loss: 4.4101 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.5630 - accuracy: 0.0222 - val_loss: 4.5134 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.6221 - accuracy: 0.0444 - val_loss: 4.5284 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.7509 - accuracy: 0.0444 - val_loss: 4.3928 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.6780 - accuracy: 0.0667 - val_loss: 4.2842 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.6321 - accuracy: 0.0222 - val_loss: 4.2257 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.5986 - accuracy: 0.0222 - val_loss: 4.2396 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.6796 - accuracy: 0.0222 - val_loss: 4.2793 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.5439 - accuracy: 0.0667 - val_loss: 4.3782 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.5203 - accuracy: 0.0667 - val_loss: 4.5341 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.5468 - accuracy: 0.0667 - val_loss: 4.6517 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.6424 - accuracy: 0.0222 - val_loss: 4.6071 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.6342 - accuracy: 0.0222 - val_loss: 4.5023 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.5870 - accuracy: 0.0444 - val_loss: 4.4390 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.4609 - accuracy: 0.0667 - val_loss: 4.5056 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.4634 - accuracy: 0.0444 - val_loss: 4.6961 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.4349 - accuracy: 0.0444 - val_loss: 5.0281 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.4262 - accuracy: 0.0444 - val_loss: 5.1187 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.6527 - accuracy: 0.0444 - val_loss: 4.6886 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.4424 - accuracy: 0.0222 - val_loss: 4.5092 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.5194 - accuracy: 0.0444 - val_loss: 4.5220 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 3.5643 - accuracy: 0.0222 - val_loss: 4.6905 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.4700 - accuracy: 0.1111 - val_loss: 5.0464 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.4860 - accuracy: 0.0222 - val_loss: 5.1201 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.4268 - accuracy: 0.0667 - val_loss: 5.0122 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.2393 - accuracy: 0.1111 - val_loss: 5.2127 - val_accuracy: 0.0000e+00\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.1889 - accuracy: 0.1556 - val_loss: 5.9666 - val_accuracy: 0.0000e+00\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 2.9805 - accuracy: 0.1778 - val_loss: 6.3159 - val_accuracy: 0.0000e+00\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.0235 - accuracy: 0.2444 - val_loss: 6.2253 - val_accuracy: 0.0000e+00\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 2.8254 - accuracy: 0.2222 - val_loss: 6.6468 - val_accuracy: 0.0000e+00\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 2.4052 - accuracy: 0.4222 - val_loss: 7.8845 - val_accuracy: 0.0000e+00\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 2.5792 - accuracy: 0.3111 - val_loss: 8.2846 - val_accuracy: 0.0000e+00\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 2.2353 - accuracy: 0.3333 - val_loss: 7.9030 - val_accuracy: 0.0000e+00\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 2.2428 - accuracy: 0.4222 - val_loss: 6.9114 - val_accuracy: 0.0000e+00\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 1.9419 - accuracy: 0.5111 - val_loss: 6.6229 - val_accuracy: 0.0000e+00\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 1.6895 - accuracy: 0.5778 - val_loss: 7.1469 - val_accuracy: 0.0833\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 1.6757 - accuracy: 0.5333 - val_loss: 7.7702 - val_accuracy: 0.0833\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 1.3979 - accuracy: 0.6667 - val_loss: 8.3568 - val_accuracy: 0.0000e+00\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 1.6809 - accuracy: 0.5778 - val_loss: 8.9235 - val_accuracy: 0.0833\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 1.2319 - accuracy: 0.6444 - val_loss: 9.1527 - val_accuracy: 0.0000e+00\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 1.4330 - accuracy: 0.5333 - val_loss: 9.2739 - val_accuracy: 0.0000e+00\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.9676 - accuracy: 0.6667 - val_loss: 9.7599 - val_accuracy: 0.0833\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 1.3783 - accuracy: 0.5556 - val_loss: 9.7598 - val_accuracy: 0.2500\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.9052 - accuracy: 0.6889 - val_loss: 9.8909 - val_accuracy: 0.2500\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.8456 - accuracy: 0.6889 - val_loss: 10.2587 - val_accuracy: 0.2500\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.9081 - accuracy: 0.6889 - val_loss: 10.4839 - val_accuracy: 0.2500\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.7247 - accuracy: 0.7556 - val_loss: 10.6645 - val_accuracy: 0.2500\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 1.0693 - accuracy: 0.6667 - val_loss: 10.1330 - val_accuracy: 0.2500\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 1.0012 - accuracy: 0.7111 - val_loss: 9.6012 - val_accuracy: 0.2500\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 1.0713 - accuracy: 0.7111 - val_loss: 8.8214 - val_accuracy: 0.2500\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.7460 - accuracy: 0.7556 - val_loss: 8.3326 - val_accuracy: 0.2500\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.6802 - accuracy: 0.7778 - val_loss: 8.5539 - val_accuracy: 0.2500\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.7021 - accuracy: 0.8889 - val_loss: 9.0909 - val_accuracy: 0.1667\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.4598 - accuracy: 0.8889 - val_loss: 9.7279 - val_accuracy: 0.1667\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.5287 - accuracy: 0.8889 - val_loss: 9.9074 - val_accuracy: 0.2500\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.5160 - accuracy: 0.8222 - val_loss: 9.7663 - val_accuracy: 0.2500\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.4092 - accuracy: 0.8889 - val_loss: 9.9643 - val_accuracy: 0.2500\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.2932 - accuracy: 0.9111 - val_loss: 10.3531 - val_accuracy: 0.2500\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.5329 - accuracy: 0.8222 - val_loss: 10.8300 - val_accuracy: 0.2500\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.5004 - accuracy: 0.8667 - val_loss: 11.0554 - val_accuracy: 0.2500\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.3810 - accuracy: 0.8667 - val_loss: 11.6598 - val_accuracy: 0.2500\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.6233 - accuracy: 0.8444 - val_loss: 11.8131 - val_accuracy: 0.2500\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.4420 - accuracy: 0.9333 - val_loss: 11.2774 - val_accuracy: 0.2500\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.3765 - accuracy: 0.9111 - val_loss: 11.0193 - val_accuracy: 0.2500\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.2608 - accuracy: 0.9111 - val_loss: 11.2962 - val_accuracy: 0.2500\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.5145 - accuracy: 0.9333 - val_loss: 11.0318 - val_accuracy: 0.2500\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.3102 - accuracy: 0.9333 - val_loss: 10.9740 - val_accuracy: 0.2500\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.3156 - accuracy: 0.9333 - val_loss: 10.9059 - val_accuracy: 0.2500\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.3222 - accuracy: 0.8667 - val_loss: 10.8054 - val_accuracy: 0.2500\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.4399 - accuracy: 0.8667 - val_loss: 10.5000 - val_accuracy: 0.2500\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.5316 - accuracy: 0.8444 - val_loss: 10.0113 - val_accuracy: 0.2500\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.3485 - accuracy: 0.9111 - val_loss: 9.6986 - val_accuracy: 0.2500\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.4310 - accuracy: 0.8889 - val_loss: 9.3718 - val_accuracy: 0.2500\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.2416 - accuracy: 0.9778 - val_loss: 9.1802 - val_accuracy: 0.2500\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.1970 - accuracy: 0.9556 - val_loss: 9.3646 - val_accuracy: 0.2500\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.3164 - accuracy: 0.9111 - val_loss: 9.6151 - val_accuracy: 0.2500\n",
            "Score for fold 4: loss of 9.30671501159668; accuracy of 14.28571492433548%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 5 ...\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 1s 463ms/step - loss: 4.0060 - accuracy: 0.0435 - val_loss: 4.0261 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.9750 - accuracy: 0.0217 - val_loss: 4.1718 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.9580 - accuracy: 0.0217 - val_loss: 4.2394 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.9039 - accuracy: 0.0217 - val_loss: 4.1729 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.9235 - accuracy: 0.0435 - val_loss: 4.1677 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.9078 - accuracy: 0.0870 - val_loss: 4.2209 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.8249 - accuracy: 0.0652 - val_loss: 4.3565 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.9704 - accuracy: 0.0000e+00 - val_loss: 4.3964 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.9276 - accuracy: 0.0217 - val_loss: 4.2671 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.9187 - accuracy: 0.0217 - val_loss: 4.1719 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.8474 - accuracy: 0.0652 - val_loss: 4.1629 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.8632 - accuracy: 0.0435 - val_loss: 4.2108 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.8444 - accuracy: 0.0217 - val_loss: 4.2966 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.7111 - accuracy: 0.0652 - val_loss: 4.4346 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.8070 - accuracy: 0.0435 - val_loss: 4.5819 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.7022 - accuracy: 0.0870 - val_loss: 4.6535 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.8045 - accuracy: 0.0000e+00 - val_loss: 4.6140 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 3.7819 - accuracy: 0.0652 - val_loss: 4.5199 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 3.7674 - accuracy: 0.0217 - val_loss: 4.4200 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.7389 - accuracy: 0.0652 - val_loss: 4.3788 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.7623 - accuracy: 0.0652 - val_loss: 4.3654 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.6750 - accuracy: 0.0435 - val_loss: 4.4510 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.8457 - accuracy: 0.0000e+00 - val_loss: 4.5099 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.7398 - accuracy: 0.0435 - val_loss: 4.5720 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.6961 - accuracy: 0.0217 - val_loss: 4.6577 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.7517 - accuracy: 0.0217 - val_loss: 4.6654 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.6923 - accuracy: 0.0217 - val_loss: 4.6108 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.6351 - accuracy: 0.0217 - val_loss: 4.6079 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.7099 - accuracy: 0.0435 - val_loss: 4.6009 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.6738 - accuracy: 0.0217 - val_loss: 4.6459 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.5722 - accuracy: 0.0652 - val_loss: 4.8113 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.7844 - accuracy: 0.0435 - val_loss: 4.8008 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.6434 - accuracy: 0.0435 - val_loss: 4.6333 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.6238 - accuracy: 0.0435 - val_loss: 4.6080 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.5379 - accuracy: 0.0652 - val_loss: 4.7946 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 3.6630 - accuracy: 0.1304 - val_loss: 4.9208 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.6122 - accuracy: 0.0217 - val_loss: 4.9141 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.7157 - accuracy: 0.0870 - val_loss: 4.7576 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.5893 - accuracy: 0.0435 - val_loss: 4.7358 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.5311 - accuracy: 0.1087 - val_loss: 4.9373 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.5732 - accuracy: 0.0435 - val_loss: 5.2561 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.5832 - accuracy: 0.0435 - val_loss: 5.3092 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.6627 - accuracy: 0.0217 - val_loss: 5.0116 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.5245 - accuracy: 0.0870 - val_loss: 4.9275 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.4995 - accuracy: 0.0870 - val_loss: 5.0178 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.5683 - accuracy: 0.0435 - val_loss: 5.1890 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.4382 - accuracy: 0.0652 - val_loss: 5.5739 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.4284 - accuracy: 0.0435 - val_loss: 5.5357 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.4194 - accuracy: 0.0870 - val_loss: 5.3836 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.4668 - accuracy: 0.0435 - val_loss: 5.7152 - val_accuracy: 0.0000e+00\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.3799 - accuracy: 0.0652 - val_loss: 6.2885 - val_accuracy: 0.0000e+00\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.3675 - accuracy: 0.0435 - val_loss: 6.1594 - val_accuracy: 0.0833\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.2862 - accuracy: 0.0652 - val_loss: 6.1007 - val_accuracy: 0.0833\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.2046 - accuracy: 0.1522 - val_loss: 6.6239 - val_accuracy: 0.0833\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.1570 - accuracy: 0.1522 - val_loss: 7.4207 - val_accuracy: 0.0833\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.2347 - accuracy: 0.1304 - val_loss: 6.8474 - val_accuracy: 0.1667\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.1150 - accuracy: 0.2174 - val_loss: 6.4581 - val_accuracy: 0.1667\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.0010 - accuracy: 0.2174 - val_loss: 6.9478 - val_accuracy: 0.1667\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 2.7731 - accuracy: 0.2174 - val_loss: 8.0257 - val_accuracy: 0.0833\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 2.5957 - accuracy: 0.2609 - val_loss: 7.6545 - val_accuracy: 0.1667\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 2.5803 - accuracy: 0.3261 - val_loss: 7.4722 - val_accuracy: 0.1667\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 2.1091 - accuracy: 0.4565 - val_loss: 8.0585 - val_accuracy: 0.1667\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 1.9903 - accuracy: 0.4783 - val_loss: 9.6493 - val_accuracy: 0.1667\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 2.0094 - accuracy: 0.3913 - val_loss: 11.1289 - val_accuracy: 0.1667\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 1.8826 - accuracy: 0.3913 - val_loss: 10.6371 - val_accuracy: 0.1667\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 1.4732 - accuracy: 0.6304 - val_loss: 9.6392 - val_accuracy: 0.1667\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 1.6251 - accuracy: 0.4565 - val_loss: 8.9894 - val_accuracy: 0.1667\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 1.5542 - accuracy: 0.5652 - val_loss: 8.4556 - val_accuracy: 0.1667\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 1.5768 - accuracy: 0.6087 - val_loss: 8.3302 - val_accuracy: 0.1667\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 1.1376 - accuracy: 0.6739 - val_loss: 8.9976 - val_accuracy: 0.1667\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 1.6497 - accuracy: 0.5870 - val_loss: 9.0339 - val_accuracy: 0.1667\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 1.2753 - accuracy: 0.6957 - val_loss: 8.3910 - val_accuracy: 0.1667\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 1.0037 - accuracy: 0.6957 - val_loss: 8.2911 - val_accuracy: 0.1667\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 1.1208 - accuracy: 0.6522 - val_loss: 8.7219 - val_accuracy: 0.1667\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.8203 - accuracy: 0.7609 - val_loss: 9.5058 - val_accuracy: 0.1667\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.9487 - accuracy: 0.6957 - val_loss: 10.3062 - val_accuracy: 0.1667\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.7619 - accuracy: 0.7609 - val_loss: 11.1372 - val_accuracy: 0.1667\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.8873 - accuracy: 0.7174 - val_loss: 10.9762 - val_accuracy: 0.1667\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 1.0481 - accuracy: 0.7609 - val_loss: 9.8621 - val_accuracy: 0.1667\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.8163 - accuracy: 0.7826 - val_loss: 9.3414 - val_accuracy: 0.1667\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.7456 - accuracy: 0.7174 - val_loss: 9.1160 - val_accuracy: 0.1667\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.5071 - accuracy: 0.8043 - val_loss: 9.7138 - val_accuracy: 0.1667\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.5822 - accuracy: 0.8043 - val_loss: 10.4679 - val_accuracy: 0.1667\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.6385 - accuracy: 0.8261 - val_loss: 10.3365 - val_accuracy: 0.1667\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.6155 - accuracy: 0.8043 - val_loss: 10.4119 - val_accuracy: 0.1667\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.7343 - accuracy: 0.6957 - val_loss: 10.7810 - val_accuracy: 0.1667\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.6009 - accuracy: 0.7826 - val_loss: 11.1587 - val_accuracy: 0.1667\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.5737 - accuracy: 0.8043 - val_loss: 11.0722 - val_accuracy: 0.1667\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.6667 - accuracy: 0.7609 - val_loss: 10.6624 - val_accuracy: 0.1667\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.3881 - accuracy: 0.8913 - val_loss: 10.8052 - val_accuracy: 0.1667\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.3811 - accuracy: 0.8478 - val_loss: 11.1158 - val_accuracy: 0.1667\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.5671 - accuracy: 0.8478 - val_loss: 11.2814 - val_accuracy: 0.1667\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.7191 - accuracy: 0.8261 - val_loss: 11.0103 - val_accuracy: 0.1667\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.4743 - accuracy: 0.8913 - val_loss: 11.0343 - val_accuracy: 0.1667\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.4858 - accuracy: 0.8913 - val_loss: 10.5847 - val_accuracy: 0.1667\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.2142 - accuracy: 0.9348 - val_loss: 9.8430 - val_accuracy: 0.1667\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.3482 - accuracy: 0.8913 - val_loss: 9.8956 - val_accuracy: 0.1667\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.4752 - accuracy: 0.8043 - val_loss: 10.1404 - val_accuracy: 0.1667\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.4763 - accuracy: 0.9130 - val_loss: 10.2535 - val_accuracy: 0.1667\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.2575 - accuracy: 0.9130 - val_loss: 10.3192 - val_accuracy: 0.1667\n",
            "Score for fold 5: loss of 5.55063009262085; accuracy of 33.33333432674408%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 6 ...\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 1s 160ms/step - loss: 4.0038 - accuracy: 0.0435 - val_loss: 4.0120 - val_accuracy: 0.0833\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 3.9833 - accuracy: 0.0217 - val_loss: 4.1179 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 3.9313 - accuracy: 0.0217 - val_loss: 4.1523 - val_accuracy: 0.0833\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 3.9155 - accuracy: 0.0870 - val_loss: 4.0919 - val_accuracy: 0.0833\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.9129 - accuracy: 0.0000e+00 - val_loss: 4.0811 - val_accuracy: 0.0833\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.9071 - accuracy: 0.0435 - val_loss: 4.0930 - val_accuracy: 0.0833\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.8838 - accuracy: 0.0000e+00 - val_loss: 4.1579 - val_accuracy: 0.0833\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 3.7927 - accuracy: 0.1087 - val_loss: 4.2676 - val_accuracy: 0.0833\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.9672 - accuracy: 0.0435 - val_loss: 4.2777 - val_accuracy: 0.0833\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 3.8734 - accuracy: 0.0435 - val_loss: 4.1752 - val_accuracy: 0.0833\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.8764 - accuracy: 0.0652 - val_loss: 4.1123 - val_accuracy: 0.0833\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.7402 - accuracy: 0.0870 - val_loss: 4.1373 - val_accuracy: 0.0833\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.7990 - accuracy: 0.0217 - val_loss: 4.2026 - val_accuracy: 0.0833\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.7214 - accuracy: 0.0652 - val_loss: 4.3251 - val_accuracy: 0.0833\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.7498 - accuracy: 0.0435 - val_loss: 4.4440 - val_accuracy: 0.0833\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.7314 - accuracy: 0.0217 - val_loss: 4.5089 - val_accuracy: 0.0833\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.6280 - accuracy: 0.0217 - val_loss: 4.5397 - val_accuracy: 0.0833\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.6853 - accuracy: 0.0217 - val_loss: 4.5101 - val_accuracy: 0.0833\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.7407 - accuracy: 0.0652 - val_loss: 4.4365 - val_accuracy: 0.0833\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.6562 - accuracy: 0.0870 - val_loss: 4.3984 - val_accuracy: 0.0833\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.6653 - accuracy: 0.0217 - val_loss: 4.4333 - val_accuracy: 0.0833\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.5878 - accuracy: 0.1304 - val_loss: 4.5712 - val_accuracy: 0.0833\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 3.5651 - accuracy: 0.0217 - val_loss: 4.7540 - val_accuracy: 0.0833\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 3.6043 - accuracy: 0.0435 - val_loss: 4.6603 - val_accuracy: 0.0833\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 3.6403 - accuracy: 0.0652 - val_loss: 4.5203 - val_accuracy: 0.0833\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 3.6741 - accuracy: 0.0435 - val_loss: 4.4582 - val_accuracy: 0.0833\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.6574 - accuracy: 0.0870 - val_loss: 4.5481 - val_accuracy: 0.0833\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.6377 - accuracy: 0.0652 - val_loss: 4.7739 - val_accuracy: 0.0833\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 3.5178 - accuracy: 0.0217 - val_loss: 5.2530 - val_accuracy: 0.0833\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 3.5943 - accuracy: 0.0870 - val_loss: 5.2755 - val_accuracy: 0.0833\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.4952 - accuracy: 0.1087 - val_loss: 5.0129 - val_accuracy: 0.0833\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.4605 - accuracy: 0.1087 - val_loss: 4.9166 - val_accuracy: 0.0833\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.3851 - accuracy: 0.1087 - val_loss: 5.4985 - val_accuracy: 0.0833\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.1737 - accuracy: 0.0870 - val_loss: 6.9114 - val_accuracy: 0.0833\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.5420 - accuracy: 0.0870 - val_loss: 5.9969 - val_accuracy: 0.0833\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.2231 - accuracy: 0.0870 - val_loss: 5.6410 - val_accuracy: 0.0833\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.1251 - accuracy: 0.1957 - val_loss: 5.9096 - val_accuracy: 0.0833\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 2.9541 - accuracy: 0.1739 - val_loss: 7.1869 - val_accuracy: 0.1667\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 2.8727 - accuracy: 0.2174 - val_loss: 8.2167 - val_accuracy: 0.1667\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 2.6786 - accuracy: 0.2826 - val_loss: 7.9898 - val_accuracy: 0.0833\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 2.8349 - accuracy: 0.2826 - val_loss: 7.5580 - val_accuracy: 0.0833\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 2.2886 - accuracy: 0.3696 - val_loss: 7.8047 - val_accuracy: 0.0833\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 2.0976 - accuracy: 0.3478 - val_loss: 9.0105 - val_accuracy: 0.1667\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 1.9063 - accuracy: 0.4130 - val_loss: 10.2736 - val_accuracy: 0.1667\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 2.2091 - accuracy: 0.2826 - val_loss: 9.4343 - val_accuracy: 0.0833\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 1.8522 - accuracy: 0.5870 - val_loss: 8.6200 - val_accuracy: 0.0833\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 1.4493 - accuracy: 0.5435 - val_loss: 9.2013 - val_accuracy: 0.0833\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 1.2777 - accuracy: 0.6304 - val_loss: 10.5072 - val_accuracy: 0.0833\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 1.1873 - accuracy: 0.5000 - val_loss: 11.5812 - val_accuracy: 0.0833\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 1.0461 - accuracy: 0.6957 - val_loss: 12.4801 - val_accuracy: 0.0833\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 1.0924 - accuracy: 0.6739 - val_loss: 12.3136 - val_accuracy: 0.1667\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.8822 - accuracy: 0.7826 - val_loss: 11.6387 - val_accuracy: 0.1667\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.7069 - accuracy: 0.8261 - val_loss: 11.8154 - val_accuracy: 0.1667\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 54ms/step - loss: 0.7131 - accuracy: 0.7826 - val_loss: 12.3755 - val_accuracy: 0.1667\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.8873 - accuracy: 0.7826 - val_loss: 12.7036 - val_accuracy: 0.1667\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.5740 - accuracy: 0.8043 - val_loss: 12.3282 - val_accuracy: 0.1667\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.5801 - accuracy: 0.8043 - val_loss: 12.0325 - val_accuracy: 0.1667\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.7000 - accuracy: 0.7826 - val_loss: 11.8695 - val_accuracy: 0.1667\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.7092 - accuracy: 0.8261 - val_loss: 11.9349 - val_accuracy: 0.1667\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.5815 - accuracy: 0.8478 - val_loss: 12.5935 - val_accuracy: 0.1667\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.4688 - accuracy: 0.7826 - val_loss: 13.3251 - val_accuracy: 0.1667\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.5162 - accuracy: 0.8043 - val_loss: 14.2005 - val_accuracy: 0.1667\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.3623 - accuracy: 0.8913 - val_loss: 14.9617 - val_accuracy: 0.1667\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.2774 - accuracy: 0.9130 - val_loss: 15.8157 - val_accuracy: 0.1667\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.2009 - accuracy: 0.9348 - val_loss: 16.9164 - val_accuracy: 0.1667\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.2834 - accuracy: 0.8478 - val_loss: 17.8329 - val_accuracy: 0.2500\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.2448 - accuracy: 0.8913 - val_loss: 18.4284 - val_accuracy: 0.2500\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.3745 - accuracy: 0.9130 - val_loss: 18.4360 - val_accuracy: 0.1667\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.3796 - accuracy: 0.8696 - val_loss: 17.5728 - val_accuracy: 0.1667\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.2225 - accuracy: 0.9783 - val_loss: 16.3989 - val_accuracy: 0.1667\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.3886 - accuracy: 0.8696 - val_loss: 15.0551 - val_accuracy: 0.1667\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.2533 - accuracy: 0.9348 - val_loss: 14.2270 - val_accuracy: 0.1667\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.2307 - accuracy: 0.8913 - val_loss: 13.6315 - val_accuracy: 0.1667\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.1333 - accuracy: 0.9348 - val_loss: 13.2471 - val_accuracy: 0.1667\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.1606 - accuracy: 0.9348 - val_loss: 13.2162 - val_accuracy: 0.1667\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.1170 - accuracy: 0.9783 - val_loss: 13.6346 - val_accuracy: 0.1667\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.1585 - accuracy: 0.9565 - val_loss: 14.3084 - val_accuracy: 0.1667\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.2622 - accuracy: 0.9130 - val_loss: 15.1649 - val_accuracy: 0.1667\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.2258 - accuracy: 0.9565 - val_loss: 16.0445 - val_accuracy: 0.1667\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.1584 - accuracy: 0.9565 - val_loss: 17.1526 - val_accuracy: 0.1667\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.1798 - accuracy: 0.9348 - val_loss: 17.6553 - val_accuracy: 0.1667\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.2800 - accuracy: 0.9130 - val_loss: 18.3981 - val_accuracy: 0.1667\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.3382 - accuracy: 0.8696 - val_loss: 18.2238 - val_accuracy: 0.1667\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.2450 - accuracy: 0.9130 - val_loss: 17.5212 - val_accuracy: 0.1667\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.1997 - accuracy: 0.9130 - val_loss: 16.5025 - val_accuracy: 0.1667\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.1609 - accuracy: 0.9130 - val_loss: 15.8130 - val_accuracy: 0.1667\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.2263 - accuracy: 0.9130 - val_loss: 15.1294 - val_accuracy: 0.1667\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.1213 - accuracy: 0.9565 - val_loss: 15.2034 - val_accuracy: 0.1667\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.2909 - accuracy: 0.8913 - val_loss: 15.8265 - val_accuracy: 0.1667\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.3287 - accuracy: 0.9130 - val_loss: 15.7255 - val_accuracy: 0.1667\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.3161 - accuracy: 0.8478 - val_loss: 15.1495 - val_accuracy: 0.0833\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.1786 - accuracy: 0.9130 - val_loss: 14.8525 - val_accuracy: 0.1667\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.1543 - accuracy: 0.9565 - val_loss: 14.8584 - val_accuracy: 0.1667\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.3171 - accuracy: 0.8913 - val_loss: 15.2028 - val_accuracy: 0.1667\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.2149 - accuracy: 0.9565 - val_loss: 15.6286 - val_accuracy: 0.1667\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.1587 - accuracy: 0.9130 - val_loss: 16.4861 - val_accuracy: 0.1667\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.2341 - accuracy: 0.9348 - val_loss: 17.1796 - val_accuracy: 0.1667\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.1292 - accuracy: 0.9565 - val_loss: 18.2773 - val_accuracy: 0.1667\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0465 - accuracy: 1.0000 - val_loss: 19.5161 - val_accuracy: 0.1667\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.2183 - accuracy: 0.9565 - val_loss: 19.8541 - val_accuracy: 0.1667\n",
            "Score for fold 6: loss of 12.899657249450684; accuracy of 33.33333432674408%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 7 ...\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 1s 153ms/step - loss: 4.0093 - accuracy: 0.0000e+00 - val_loss: 4.0134 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 4.0034 - accuracy: 0.0000e+00 - val_loss: 4.0269 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.9911 - accuracy: 0.0000e+00 - val_loss: 4.0572 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.9459 - accuracy: 0.0217 - val_loss: 4.1599 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.9540 - accuracy: 0.0217 - val_loss: 4.2682 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.9185 - accuracy: 0.0652 - val_loss: 4.2333 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.9771 - accuracy: 0.0000e+00 - val_loss: 4.2039 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.8662 - accuracy: 0.0652 - val_loss: 4.2191 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.9009 - accuracy: 0.0652 - val_loss: 4.2285 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.7963 - accuracy: 0.0652 - val_loss: 4.2511 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.7721 - accuracy: 0.0652 - val_loss: 4.3624 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.8185 - accuracy: 0.0435 - val_loss: 4.4995 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.7358 - accuracy: 0.0652 - val_loss: 4.5508 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.9319 - accuracy: 0.0000e+00 - val_loss: 4.3927 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.8316 - accuracy: 0.0000e+00 - val_loss: 4.2757 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 3.7567 - accuracy: 0.0652 - val_loss: 4.2764 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 3.6281 - accuracy: 0.1087 - val_loss: 4.4009 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.7965 - accuracy: 0.0217 - val_loss: 4.5527 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.5627 - accuracy: 0.0870 - val_loss: 4.6979 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 3.6233 - accuracy: 0.0652 - val_loss: 4.8871 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 3.8097 - accuracy: 0.0652 - val_loss: 4.8639 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.6062 - accuracy: 0.0652 - val_loss: 4.7273 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.7720 - accuracy: 0.0435 - val_loss: 4.5528 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 3.6189 - accuracy: 0.0652 - val_loss: 4.4989 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.7143 - accuracy: 0.0217 - val_loss: 4.5173 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.7962 - accuracy: 0.0435 - val_loss: 4.5639 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 3.6182 - accuracy: 0.0652 - val_loss: 4.7033 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 3.7432 - accuracy: 0.0000e+00 - val_loss: 4.8291 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 3.4753 - accuracy: 0.1304 - val_loss: 5.0190 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.5864 - accuracy: 0.0217 - val_loss: 5.1641 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.6249 - accuracy: 0.0217 - val_loss: 5.0793 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.6157 - accuracy: 0.0652 - val_loss: 4.8866 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 3.5098 - accuracy: 0.0870 - val_loss: 5.0029 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 3.6174 - accuracy: 0.0870 - val_loss: 5.2651 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.5197 - accuracy: 0.1087 - val_loss: 5.5507 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.3911 - accuracy: 0.0652 - val_loss: 5.8551 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.4333 - accuracy: 0.1087 - val_loss: 5.8116 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 3.4130 - accuracy: 0.0652 - val_loss: 5.9697 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.4105 - accuracy: 0.1304 - val_loss: 5.8639 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.3261 - accuracy: 0.1739 - val_loss: 5.9198 - val_accuracy: 0.0833\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.3500 - accuracy: 0.1522 - val_loss: 6.2529 - val_accuracy: 0.0833\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.0611 - accuracy: 0.1522 - val_loss: 6.9917 - val_accuracy: 0.0833\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.3463 - accuracy: 0.1522 - val_loss: 6.9100 - val_accuracy: 0.0833\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 2.9567 - accuracy: 0.2174 - val_loss: 6.6649 - val_accuracy: 0.0833\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 2.8838 - accuracy: 0.1739 - val_loss: 7.2313 - val_accuracy: 0.0833\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 2.9376 - accuracy: 0.3043 - val_loss: 7.3236 - val_accuracy: 0.0833\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 2.6463 - accuracy: 0.3261 - val_loss: 7.2952 - val_accuracy: 0.0833\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 2.6033 - accuracy: 0.2826 - val_loss: 7.8638 - val_accuracy: 0.0833\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 2.3378 - accuracy: 0.3043 - val_loss: 8.4176 - val_accuracy: 0.0833\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 2.3714 - accuracy: 0.3043 - val_loss: 8.5971 - val_accuracy: 0.0833\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 2.1124 - accuracy: 0.3478 - val_loss: 8.6146 - val_accuracy: 0.0833\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 1.8747 - accuracy: 0.4130 - val_loss: 8.6252 - val_accuracy: 0.0833\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 1.4343 - accuracy: 0.6522 - val_loss: 9.2633 - val_accuracy: 0.0833\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 1.7373 - accuracy: 0.5217 - val_loss: 9.7733 - val_accuracy: 0.0833\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 1.6890 - accuracy: 0.6087 - val_loss: 9.6467 - val_accuracy: 0.1667\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 1.4020 - accuracy: 0.5652 - val_loss: 9.9737 - val_accuracy: 0.1667\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 1.1191 - accuracy: 0.6957 - val_loss: 10.4238 - val_accuracy: 0.1667\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 1.4355 - accuracy: 0.6304 - val_loss: 10.3827 - val_accuracy: 0.1667\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 1.0359 - accuracy: 0.6522 - val_loss: 10.0994 - val_accuracy: 0.1667\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.9256 - accuracy: 0.7174 - val_loss: 10.2799 - val_accuracy: 0.1667\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.9235 - accuracy: 0.7391 - val_loss: 11.0451 - val_accuracy: 0.1667\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 1.0774 - accuracy: 0.6522 - val_loss: 12.0129 - val_accuracy: 0.1667\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.9136 - accuracy: 0.7174 - val_loss: 12.5640 - val_accuracy: 0.1667\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.2170 - accuracy: 0.9348 - val_loss: 13.7630 - val_accuracy: 0.0833\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.8913 - accuracy: 0.7609 - val_loss: 14.0649 - val_accuracy: 0.0833\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.5794 - accuracy: 0.8261 - val_loss: 13.8296 - val_accuracy: 0.1667\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.4819 - accuracy: 0.9130 - val_loss: 13.0001 - val_accuracy: 0.1667\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.6721 - accuracy: 0.7391 - val_loss: 12.8110 - val_accuracy: 0.1667\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.5328 - accuracy: 0.8696 - val_loss: 13.0078 - val_accuracy: 0.1667\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.5906 - accuracy: 0.8478 - val_loss: 13.5727 - val_accuracy: 0.1667\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.7381 - accuracy: 0.8043 - val_loss: 13.8116 - val_accuracy: 0.1667\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.5814 - accuracy: 0.8696 - val_loss: 14.5567 - val_accuracy: 0.1667\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.4703 - accuracy: 0.8261 - val_loss: 15.2706 - val_accuracy: 0.1667\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.4656 - accuracy: 0.8696 - val_loss: 15.8073 - val_accuracy: 0.1667\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.6521 - accuracy: 0.7609 - val_loss: 15.6934 - val_accuracy: 0.1667\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.4658 - accuracy: 0.8696 - val_loss: 15.6278 - val_accuracy: 0.1667\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.5942 - accuracy: 0.7826 - val_loss: 15.1953 - val_accuracy: 0.1667\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.6141 - accuracy: 0.8696 - val_loss: 14.8339 - val_accuracy: 0.1667\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.3418 - accuracy: 0.9565 - val_loss: 14.7409 - val_accuracy: 0.1667\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.3268 - accuracy: 0.8696 - val_loss: 15.0315 - val_accuracy: 0.1667\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.4497 - accuracy: 0.8478 - val_loss: 15.6061 - val_accuracy: 0.1667\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.4423 - accuracy: 0.8261 - val_loss: 16.4371 - val_accuracy: 0.1667\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.3870 - accuracy: 0.9565 - val_loss: 16.8991 - val_accuracy: 0.1667\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.3352 - accuracy: 0.8696 - val_loss: 16.6639 - val_accuracy: 0.1667\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.5418 - accuracy: 0.8913 - val_loss: 16.2219 - val_accuracy: 0.1667\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.3282 - accuracy: 0.9348 - val_loss: 16.2718 - val_accuracy: 0.1667\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.2001 - accuracy: 0.9348 - val_loss: 16.4548 - val_accuracy: 0.1667\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.2520 - accuracy: 0.9565 - val_loss: 16.5220 - val_accuracy: 0.1667\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.3907 - accuracy: 0.9130 - val_loss: 16.1306 - val_accuracy: 0.1667\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.2694 - accuracy: 0.8913 - val_loss: 15.8682 - val_accuracy: 0.1667\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.4164 - accuracy: 0.8261 - val_loss: 15.7034 - val_accuracy: 0.1667\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.4293 - accuracy: 0.9130 - val_loss: 15.1427 - val_accuracy: 0.1667\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.1543 - accuracy: 0.9565 - val_loss: 14.6211 - val_accuracy: 0.1667\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.2961 - accuracy: 0.9565 - val_loss: 14.1574 - val_accuracy: 0.1667\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 40ms/step - loss: 0.2478 - accuracy: 0.9348 - val_loss: 13.9942 - val_accuracy: 0.1667\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.1953 - accuracy: 0.9348 - val_loss: 14.6398 - val_accuracy: 0.1667\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.2031 - accuracy: 0.9348 - val_loss: 15.5327 - val_accuracy: 0.1667\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.3593 - accuracy: 0.9130 - val_loss: 15.6587 - val_accuracy: 0.1667\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.2724 - accuracy: 0.8696 - val_loss: 15.5039 - val_accuracy: 0.1667\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.2450 - accuracy: 0.9130 - val_loss: 15.3254 - val_accuracy: 0.1667\n",
            "Score for fold 7: loss of 7.351945877075195; accuracy of 16.66666716337204%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 8 ...\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 1s 145ms/step - loss: 4.0076 - accuracy: 0.0000e+00 - val_loss: 4.0119 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.9931 - accuracy: 0.0000e+00 - val_loss: 4.0343 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.9843 - accuracy: 0.0217 - val_loss: 4.0597 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.8861 - accuracy: 0.0217 - val_loss: 4.0730 - val_accuracy: 0.0833\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.8070 - accuracy: 0.0217 - val_loss: 4.1082 - val_accuracy: 0.0833\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.7950 - accuracy: 0.0435 - val_loss: 4.1966 - val_accuracy: 0.0833\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 4.0436 - accuracy: 0.0435 - val_loss: 4.1620 - val_accuracy: 0.0833\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.9064 - accuracy: 0.0435 - val_loss: 4.0927 - val_accuracy: 0.0833\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.8140 - accuracy: 0.0652 - val_loss: 4.0740 - val_accuracy: 0.0833\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.8526 - accuracy: 0.0870 - val_loss: 4.0785 - val_accuracy: 0.0833\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 3.8944 - accuracy: 0.0652 - val_loss: 4.0904 - val_accuracy: 0.0833\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.9361 - accuracy: 0.0000e+00 - val_loss: 4.1107 - val_accuracy: 0.0833\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.8306 - accuracy: 0.0652 - val_loss: 4.1398 - val_accuracy: 0.0833\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.7904 - accuracy: 0.0870 - val_loss: 4.1945 - val_accuracy: 0.0833\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.7180 - accuracy: 0.0435 - val_loss: 4.2905 - val_accuracy: 0.0833\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.7650 - accuracy: 0.0435 - val_loss: 4.3904 - val_accuracy: 0.0833\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.8467 - accuracy: 0.0217 - val_loss: 4.4023 - val_accuracy: 0.0833\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.7683 - accuracy: 0.0652 - val_loss: 4.3454 - val_accuracy: 0.0833\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.8232 - accuracy: 0.0435 - val_loss: 4.2902 - val_accuracy: 0.0833\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.7325 - accuracy: 0.0217 - val_loss: 4.2755 - val_accuracy: 0.0833\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.5966 - accuracy: 0.0435 - val_loss: 4.3179 - val_accuracy: 0.0833\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.7133 - accuracy: 0.0652 - val_loss: 4.4073 - val_accuracy: 0.0833\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.6931 - accuracy: 0.0000e+00 - val_loss: 4.4753 - val_accuracy: 0.0833\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.6706 - accuracy: 0.0217 - val_loss: 4.4800 - val_accuracy: 0.0833\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.6124 - accuracy: 0.0435 - val_loss: 4.4821 - val_accuracy: 0.0833\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.6388 - accuracy: 0.0217 - val_loss: 4.5022 - val_accuracy: 0.0833\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.7402 - accuracy: 0.0000e+00 - val_loss: 4.4599 - val_accuracy: 0.0833\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.6025 - accuracy: 0.0652 - val_loss: 4.4450 - val_accuracy: 0.0833\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.6419 - accuracy: 0.0652 - val_loss: 4.4149 - val_accuracy: 0.0833\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.5549 - accuracy: 0.0217 - val_loss: 4.4301 - val_accuracy: 0.0833\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 3.6598 - accuracy: 0.0217 - val_loss: 4.4431 - val_accuracy: 0.0833\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.6779 - accuracy: 0.0435 - val_loss: 4.4296 - val_accuracy: 0.0833\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.6571 - accuracy: 0.0870 - val_loss: 4.4067 - val_accuracy: 0.0833\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.5555 - accuracy: 0.0435 - val_loss: 4.4149 - val_accuracy: 0.0833\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.5455 - accuracy: 0.0000e+00 - val_loss: 4.5413 - val_accuracy: 0.0833\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.6775 - accuracy: 0.0435 - val_loss: 4.5968 - val_accuracy: 0.0833\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.6291 - accuracy: 0.0217 - val_loss: 4.5674 - val_accuracy: 0.0833\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.4179 - accuracy: 0.0652 - val_loss: 4.6147 - val_accuracy: 0.0833\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.5338 - accuracy: 0.1087 - val_loss: 4.7082 - val_accuracy: 0.0833\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.7317 - accuracy: 0.0217 - val_loss: 4.6550 - val_accuracy: 0.0833\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 3.6647 - accuracy: 0.0217 - val_loss: 4.5014 - val_accuracy: 0.0833\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.6933 - accuracy: 0.0217 - val_loss: 4.3782 - val_accuracy: 0.0833\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.5957 - accuracy: 0.0652 - val_loss: 4.3728 - val_accuracy: 0.0833\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.6012 - accuracy: 0.0652 - val_loss: 4.5018 - val_accuracy: 0.0833\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.6068 - accuracy: 0.0652 - val_loss: 4.6922 - val_accuracy: 0.0833\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.6475 - accuracy: 0.0435 - val_loss: 4.6843 - val_accuracy: 0.0833\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.5235 - accuracy: 0.0870 - val_loss: 4.6890 - val_accuracy: 0.0833\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.6433 - accuracy: 0.0217 - val_loss: 4.6224 - val_accuracy: 0.0833\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.5622 - accuracy: 0.0870 - val_loss: 4.5424 - val_accuracy: 0.0833\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.5984 - accuracy: 0.0217 - val_loss: 4.5610 - val_accuracy: 0.0833\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.5158 - accuracy: 0.0217 - val_loss: 4.6943 - val_accuracy: 0.0833\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.6151 - accuracy: 0.0217 - val_loss: 4.7558 - val_accuracy: 0.0833\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.4929 - accuracy: 0.0870 - val_loss: 4.7491 - val_accuracy: 0.0833\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.4855 - accuracy: 0.0652 - val_loss: 4.8675 - val_accuracy: 0.0833\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.5358 - accuracy: 0.0000e+00 - val_loss: 4.9907 - val_accuracy: 0.0833\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.3463 - accuracy: 0.1087 - val_loss: 5.1019 - val_accuracy: 0.0833\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.4696 - accuracy: 0.1522 - val_loss: 5.0145 - val_accuracy: 0.0833\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 3.4398 - accuracy: 0.0217 - val_loss: 5.1837 - val_accuracy: 0.0833\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.3773 - accuracy: 0.0652 - val_loss: 5.3916 - val_accuracy: 0.0833\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.2820 - accuracy: 0.0870 - val_loss: 5.4299 - val_accuracy: 0.0833\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.2346 - accuracy: 0.1087 - val_loss: 5.6871 - val_accuracy: 0.0833\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.1764 - accuracy: 0.1087 - val_loss: 5.6475 - val_accuracy: 0.0833\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 3.1365 - accuracy: 0.1957 - val_loss: 5.5592 - val_accuracy: 0.0833\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.0676 - accuracy: 0.1087 - val_loss: 5.7919 - val_accuracy: 0.0833\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 2.8623 - accuracy: 0.3043 - val_loss: 5.9889 - val_accuracy: 0.0833\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 2.7090 - accuracy: 0.2174 - val_loss: 6.1655 - val_accuracy: 0.0833\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 2.6536 - accuracy: 0.2826 - val_loss: 6.7910 - val_accuracy: 0.0833\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 2.4842 - accuracy: 0.3696 - val_loss: 7.5959 - val_accuracy: 0.0833\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 2.0884 - accuracy: 0.4130 - val_loss: 7.9988 - val_accuracy: 0.0833\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 2.3584 - accuracy: 0.3261 - val_loss: 7.7339 - val_accuracy: 0.0833\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 1.6282 - accuracy: 0.5000 - val_loss: 7.3603 - val_accuracy: 0.0833\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 1.6500 - accuracy: 0.4565 - val_loss: 7.6597 - val_accuracy: 0.1667\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 1.7890 - accuracy: 0.4348 - val_loss: 7.5394 - val_accuracy: 0.0833\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 1.4149 - accuracy: 0.5217 - val_loss: 7.6007 - val_accuracy: 0.0833\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 1.2440 - accuracy: 0.6739 - val_loss: 8.5784 - val_accuracy: 0.0833\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 1.3906 - accuracy: 0.6522 - val_loss: 10.1960 - val_accuracy: 0.0833\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 1.1639 - accuracy: 0.6087 - val_loss: 10.9512 - val_accuracy: 0.0833\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 1.3673 - accuracy: 0.6087 - val_loss: 10.7275 - val_accuracy: 0.0833\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 1.0867 - accuracy: 0.6957 - val_loss: 10.9439 - val_accuracy: 0.0833\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 1.0475 - accuracy: 0.6957 - val_loss: 11.1085 - val_accuracy: 0.0833\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 1.1287 - accuracy: 0.7609 - val_loss: 11.2942 - val_accuracy: 0.0833\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.9375 - accuracy: 0.7826 - val_loss: 10.5588 - val_accuracy: 0.1667\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.5846 - accuracy: 0.8478 - val_loss: 9.7951 - val_accuracy: 0.0833\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.6785 - accuracy: 0.7826 - val_loss: 9.9309 - val_accuracy: 0.0833\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.8568 - accuracy: 0.7391 - val_loss: 10.7970 - val_accuracy: 0.1667\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.7583 - accuracy: 0.7826 - val_loss: 11.4966 - val_accuracy: 0.1667\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.7856 - accuracy: 0.8043 - val_loss: 11.8659 - val_accuracy: 0.1667\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.8593 - accuracy: 0.7609 - val_loss: 11.4800 - val_accuracy: 0.1667\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.5290 - accuracy: 0.8478 - val_loss: 11.1627 - val_accuracy: 0.1667\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.7855 - accuracy: 0.7826 - val_loss: 10.7051 - val_accuracy: 0.1667\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.8587 - accuracy: 0.7391 - val_loss: 10.1648 - val_accuracy: 0.1667\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.9871 - accuracy: 0.8043 - val_loss: 9.5800 - val_accuracy: 0.1667\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.8484 - accuracy: 0.7174 - val_loss: 9.5015 - val_accuracy: 0.2500\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.6189 - accuracy: 0.8261 - val_loss: 9.8535 - val_accuracy: 0.2500\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.6740 - accuracy: 0.8043 - val_loss: 10.1145 - val_accuracy: 0.2500\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.4625 - accuracy: 0.8696 - val_loss: 10.3625 - val_accuracy: 0.2500\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.7307 - accuracy: 0.7391 - val_loss: 10.0819 - val_accuracy: 0.2500\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.3771 - accuracy: 0.8696 - val_loss: 9.9124 - val_accuracy: 0.2500\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.5269 - accuracy: 0.8478 - val_loss: 9.7885 - val_accuracy: 0.2500\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.3700 - accuracy: 0.9130 - val_loss: 9.9257 - val_accuracy: 0.2500\n",
            "Score for fold 8: loss of 7.936411380767822; accuracy of 33.33333432674408%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 9 ...\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 0s 145ms/step - loss: 4.0075 - accuracy: 0.0000e+00 - val_loss: 4.0034 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.9824 - accuracy: 0.0870 - val_loss: 3.9966 - val_accuracy: 0.0833\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.9111 - accuracy: 0.0217 - val_loss: 4.0774 - val_accuracy: 0.0833\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.9688 - accuracy: 0.0000e+00 - val_loss: 4.0952 - val_accuracy: 0.0833\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.8375 - accuracy: 0.0652 - val_loss: 4.1121 - val_accuracy: 0.0833\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.9208 - accuracy: 0.0217 - val_loss: 4.1045 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.6908 - accuracy: 0.0870 - val_loss: 4.0941 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.8104 - accuracy: 0.0217 - val_loss: 4.1014 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 3.8480 - accuracy: 0.0435 - val_loss: 4.1085 - val_accuracy: 0.0000e+00\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.8053 - accuracy: 0.0435 - val_loss: 4.1213 - val_accuracy: 0.0000e+00\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.7968 - accuracy: 0.0217 - val_loss: 4.1530 - val_accuracy: 0.0000e+00\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 3.6806 - accuracy: 0.0870 - val_loss: 4.2158 - val_accuracy: 0.0000e+00\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.8492 - accuracy: 0.0870 - val_loss: 4.2171 - val_accuracy: 0.0000e+00\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.7380 - accuracy: 0.0435 - val_loss: 4.1878 - val_accuracy: 0.0000e+00\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.5824 - accuracy: 0.0870 - val_loss: 4.2233 - val_accuracy: 0.0000e+00\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.7504 - accuracy: 0.0652 - val_loss: 4.3012 - val_accuracy: 0.0000e+00\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.7467 - accuracy: 0.0217 - val_loss: 4.2940 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 3.6448 - accuracy: 0.0217 - val_loss: 4.3144 - val_accuracy: 0.0833\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.6869 - accuracy: 0.0217 - val_loss: 4.3668 - val_accuracy: 0.0833\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.6811 - accuracy: 0.0435 - val_loss: 4.5151 - val_accuracy: 0.0833\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.4725 - accuracy: 0.1522 - val_loss: 4.9585 - val_accuracy: 0.0833\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.3163 - accuracy: 0.1304 - val_loss: 5.2016 - val_accuracy: 0.0833\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 3.5199 - accuracy: 0.0652 - val_loss: 4.8959 - val_accuracy: 0.0833\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.3094 - accuracy: 0.1957 - val_loss: 5.3003 - val_accuracy: 0.0833\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.4565 - accuracy: 0.0870 - val_loss: 6.1054 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.3555 - accuracy: 0.1304 - val_loss: 5.8347 - val_accuracy: 0.0833\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.0862 - accuracy: 0.1304 - val_loss: 5.6526 - val_accuracy: 0.0833\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.0281 - accuracy: 0.2391 - val_loss: 6.2489 - val_accuracy: 0.0833\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 2.9375 - accuracy: 0.2391 - val_loss: 7.0536 - val_accuracy: 0.0833\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 2.6548 - accuracy: 0.2391 - val_loss: 6.9722 - val_accuracy: 0.0833\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 2.2948 - accuracy: 0.4783 - val_loss: 7.4469 - val_accuracy: 0.0833\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 2.0157 - accuracy: 0.4130 - val_loss: 7.7436 - val_accuracy: 0.0833\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 1.8862 - accuracy: 0.4130 - val_loss: 7.5933 - val_accuracy: 0.1667\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 2.1174 - accuracy: 0.4565 - val_loss: 8.1688 - val_accuracy: 0.1667\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 1.6936 - accuracy: 0.4783 - val_loss: 9.0182 - val_accuracy: 0.1667\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 1.4903 - accuracy: 0.6087 - val_loss: 10.6064 - val_accuracy: 0.0833\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 1.3334 - accuracy: 0.5870 - val_loss: 10.8328 - val_accuracy: 0.0833\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 1.1157 - accuracy: 0.6739 - val_loss: 10.9160 - val_accuracy: 0.1667\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 1.4036 - accuracy: 0.5652 - val_loss: 11.2643 - val_accuracy: 0.1667\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.8947 - accuracy: 0.7609 - val_loss: 11.2810 - val_accuracy: 0.1667\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 1.0669 - accuracy: 0.7174 - val_loss: 11.0148 - val_accuracy: 0.1667\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.9957 - accuracy: 0.6522 - val_loss: 11.6616 - val_accuracy: 0.1667\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.9938 - accuracy: 0.6957 - val_loss: 13.7031 - val_accuracy: 0.1667\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.8144 - accuracy: 0.7174 - val_loss: 15.7724 - val_accuracy: 0.2500\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.7405 - accuracy: 0.7609 - val_loss: 16.3781 - val_accuracy: 0.2500\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.5980 - accuracy: 0.8043 - val_loss: 16.7762 - val_accuracy: 0.2500\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.6767 - accuracy: 0.8043 - val_loss: 16.7321 - val_accuracy: 0.2500\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.6335 - accuracy: 0.8478 - val_loss: 17.0759 - val_accuracy: 0.2500\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.6199 - accuracy: 0.8043 - val_loss: 17.2745 - val_accuracy: 0.2500\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.5200 - accuracy: 0.8696 - val_loss: 17.2915 - val_accuracy: 0.2500\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.4506 - accuracy: 0.8478 - val_loss: 17.1811 - val_accuracy: 0.2500\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.5285 - accuracy: 0.8043 - val_loss: 17.3449 - val_accuracy: 0.2500\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.4255 - accuracy: 0.8696 - val_loss: 17.6440 - val_accuracy: 0.2500\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.2996 - accuracy: 0.9130 - val_loss: 18.7323 - val_accuracy: 0.2500\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.6079 - accuracy: 0.7826 - val_loss: 18.5249 - val_accuracy: 0.2500\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.5720 - accuracy: 0.8261 - val_loss: 16.8658 - val_accuracy: 0.2500\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.3675 - accuracy: 0.8696 - val_loss: 16.0671 - val_accuracy: 0.2500\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.3009 - accuracy: 0.9348 - val_loss: 16.1030 - val_accuracy: 0.2500\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.1851 - accuracy: 0.9348 - val_loss: 16.4912 - val_accuracy: 0.2500\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.2502 - accuracy: 0.9348 - val_loss: 17.4088 - val_accuracy: 0.2500\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.2627 - accuracy: 0.9130 - val_loss: 18.6584 - val_accuracy: 0.2500\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.2954 - accuracy: 0.8913 - val_loss: 19.6648 - val_accuracy: 0.2500\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.3091 - accuracy: 0.8913 - val_loss: 20.3252 - val_accuracy: 0.2500\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 0.3376 - accuracy: 0.8913 - val_loss: 19.8068 - val_accuracy: 0.2500\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.2908 - accuracy: 0.8913 - val_loss: 19.1972 - val_accuracy: 0.2500\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.2956 - accuracy: 0.8913 - val_loss: 19.4844 - val_accuracy: 0.2500\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.2151 - accuracy: 0.9348 - val_loss: 20.8257 - val_accuracy: 0.2500\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.1161 - accuracy: 0.9783 - val_loss: 22.4434 - val_accuracy: 0.2500\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.4181 - accuracy: 0.8696 - val_loss: 22.9107 - val_accuracy: 0.2500\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.1956 - accuracy: 0.9565 - val_loss: 22.4065 - val_accuracy: 0.2500\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.3247 - accuracy: 0.9130 - val_loss: 20.5966 - val_accuracy: 0.2500\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.2412 - accuracy: 0.8913 - val_loss: 17.5244 - val_accuracy: 0.2500\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.2173 - accuracy: 0.9348 - val_loss: 15.7950 - val_accuracy: 0.2500\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.3422 - accuracy: 0.8913 - val_loss: 15.1743 - val_accuracy: 0.2500\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 57ms/step - loss: 0.1602 - accuracy: 0.9130 - val_loss: 15.0018 - val_accuracy: 0.2500\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.1617 - accuracy: 0.9783 - val_loss: 15.7214 - val_accuracy: 0.2500\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.2321 - accuracy: 0.9348 - val_loss: 15.9510 - val_accuracy: 0.2500\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.2331 - accuracy: 0.9565 - val_loss: 16.7679 - val_accuracy: 0.2500\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.1977 - accuracy: 0.9783 - val_loss: 17.5866 - val_accuracy: 0.2500\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.1503 - accuracy: 0.9565 - val_loss: 18.1589 - val_accuracy: 0.2500\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.3375 - accuracy: 0.8913 - val_loss: 17.9897 - val_accuracy: 0.2500\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.3570 - accuracy: 0.8696 - val_loss: 17.5813 - val_accuracy: 0.2500\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.1422 - accuracy: 0.9565 - val_loss: 17.8711 - val_accuracy: 0.2500\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 0.3426 - accuracy: 0.9130 - val_loss: 18.6451 - val_accuracy: 0.2500\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.1707 - accuracy: 0.9565 - val_loss: 20.0011 - val_accuracy: 0.2500\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.1498 - accuracy: 0.9348 - val_loss: 21.4842 - val_accuracy: 0.2500\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0867 - accuracy: 0.9783 - val_loss: 22.3399 - val_accuracy: 0.2500\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.0458 - accuracy: 0.9783 - val_loss: 23.2634 - val_accuracy: 0.2500\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 52ms/step - loss: 0.2333 - accuracy: 0.9348 - val_loss: 23.8383 - val_accuracy: 0.2500\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.0442 - accuracy: 1.0000 - val_loss: 24.2291 - val_accuracy: 0.2500\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.1152 - accuracy: 0.9783 - val_loss: 24.6625 - val_accuracy: 0.2500\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.1442 - accuracy: 0.9783 - val_loss: 24.5988 - val_accuracy: 0.2500\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.0905 - accuracy: 0.9565 - val_loss: 24.1468 - val_accuracy: 0.2500\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 50ms/step - loss: 0.3287 - accuracy: 0.8913 - val_loss: 21.9095 - val_accuracy: 0.2500\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.0942 - accuracy: 0.9565 - val_loss: 19.9175 - val_accuracy: 0.2500\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 0.1708 - accuracy: 0.9565 - val_loss: 18.3565 - val_accuracy: 0.2500\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 49ms/step - loss: 0.1546 - accuracy: 0.9348 - val_loss: 17.4929 - val_accuracy: 0.2500\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 0.1130 - accuracy: 0.9783 - val_loss: 17.8232 - val_accuracy: 0.2500\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 55ms/step - loss: 0.1732 - accuracy: 0.9565 - val_loss: 18.0843 - val_accuracy: 0.2500\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 0.1535 - accuracy: 0.9348 - val_loss: 18.3698 - val_accuracy: 0.2500\n",
            "Score for fold 9: loss of 13.110926628112793; accuracy of 0.0%\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 10 ...\n",
            "Epoch 1/100\n",
            "2/2 [==============================] - 1s 157ms/step - loss: 4.0084 - accuracy: 0.0217 - val_loss: 4.0033 - val_accuracy: 0.0000e+00\n",
            "Epoch 2/100\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 3.9889 - accuracy: 0.0217 - val_loss: 3.9934 - val_accuracy: 0.0000e+00\n",
            "Epoch 3/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.9047 - accuracy: 0.0435 - val_loss: 4.0450 - val_accuracy: 0.0000e+00\n",
            "Epoch 4/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.8182 - accuracy: 0.0217 - val_loss: 4.1443 - val_accuracy: 0.0000e+00\n",
            "Epoch 5/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.8233 - accuracy: 0.0435 - val_loss: 4.1819 - val_accuracy: 0.0000e+00\n",
            "Epoch 6/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.9108 - accuracy: 0.0652 - val_loss: 4.0767 - val_accuracy: 0.0000e+00\n",
            "Epoch 7/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.8400 - accuracy: 0.0217 - val_loss: 4.0254 - val_accuracy: 0.0000e+00\n",
            "Epoch 8/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.7938 - accuracy: 0.0870 - val_loss: 4.0211 - val_accuracy: 0.0000e+00\n",
            "Epoch 9/100\n",
            "2/2 [==============================] - 0s 48ms/step - loss: 3.8593 - accuracy: 0.0435 - val_loss: 4.0358 - val_accuracy: 0.0833\n",
            "Epoch 10/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.8581 - accuracy: 0.0217 - val_loss: 4.0673 - val_accuracy: 0.0833\n",
            "Epoch 11/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.7886 - accuracy: 0.0217 - val_loss: 4.1120 - val_accuracy: 0.0833\n",
            "Epoch 12/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.6607 - accuracy: 0.0435 - val_loss: 4.2054 - val_accuracy: 0.0833\n",
            "Epoch 13/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.6488 - accuracy: 0.0217 - val_loss: 4.3245 - val_accuracy: 0.0833\n",
            "Epoch 14/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.6131 - accuracy: 0.0652 - val_loss: 4.3860 - val_accuracy: 0.0833\n",
            "Epoch 15/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.8022 - accuracy: 0.0435 - val_loss: 4.3404 - val_accuracy: 0.0833\n",
            "Epoch 16/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 3.7430 - accuracy: 0.0217 - val_loss: 4.2641 - val_accuracy: 0.0833\n",
            "Epoch 17/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.6737 - accuracy: 0.0435 - val_loss: 4.2099 - val_accuracy: 0.0000e+00\n",
            "Epoch 18/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.6734 - accuracy: 0.0217 - val_loss: 4.1906 - val_accuracy: 0.0000e+00\n",
            "Epoch 19/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.8089 - accuracy: 0.0217 - val_loss: 4.1766 - val_accuracy: 0.0000e+00\n",
            "Epoch 20/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.6425 - accuracy: 0.0435 - val_loss: 4.2331 - val_accuracy: 0.0000e+00\n",
            "Epoch 21/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.5632 - accuracy: 0.0870 - val_loss: 4.3535 - val_accuracy: 0.0000e+00\n",
            "Epoch 22/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.8171 - accuracy: 0.0435 - val_loss: 4.4358 - val_accuracy: 0.0000e+00\n",
            "Epoch 23/100\n",
            "2/2 [==============================] - 0s 51ms/step - loss: 3.5966 - accuracy: 0.0000e+00 - val_loss: 4.4607 - val_accuracy: 0.0000e+00\n",
            "Epoch 24/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 3.6906 - accuracy: 0.0652 - val_loss: 4.4394 - val_accuracy: 0.0000e+00\n",
            "Epoch 25/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 3.5999 - accuracy: 0.0435 - val_loss: 4.3927 - val_accuracy: 0.0000e+00\n",
            "Epoch 26/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.5825 - accuracy: 0.0870 - val_loss: 4.3851 - val_accuracy: 0.0000e+00\n",
            "Epoch 27/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 3.5713 - accuracy: 0.0435 - val_loss: 4.4215 - val_accuracy: 0.0000e+00\n",
            "Epoch 28/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.5290 - accuracy: 0.0870 - val_loss: 4.5229 - val_accuracy: 0.0000e+00\n",
            "Epoch 29/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.5985 - accuracy: 0.0652 - val_loss: 4.6093 - val_accuracy: 0.0000e+00\n",
            "Epoch 30/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.6162 - accuracy: 0.0000e+00 - val_loss: 4.6612 - val_accuracy: 0.0000e+00\n",
            "Epoch 31/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.7049 - accuracy: 0.0000e+00 - val_loss: 4.6083 - val_accuracy: 0.0000e+00\n",
            "Epoch 32/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.7894 - accuracy: 0.0870 - val_loss: 4.4454 - val_accuracy: 0.0000e+00\n",
            "Epoch 33/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.6017 - accuracy: 0.0217 - val_loss: 4.3472 - val_accuracy: 0.0000e+00\n",
            "Epoch 34/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.5042 - accuracy: 0.0870 - val_loss: 4.3951 - val_accuracy: 0.0000e+00\n",
            "Epoch 35/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.5785 - accuracy: 0.0652 - val_loss: 4.5361 - val_accuracy: 0.0000e+00\n",
            "Epoch 36/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.5614 - accuracy: 0.0652 - val_loss: 4.6859 - val_accuracy: 0.0000e+00\n",
            "Epoch 37/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.5892 - accuracy: 0.0217 - val_loss: 4.7548 - val_accuracy: 0.0000e+00\n",
            "Epoch 38/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 3.6879 - accuracy: 0.0435 - val_loss: 4.6487 - val_accuracy: 0.0000e+00\n",
            "Epoch 39/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 3.5827 - accuracy: 0.0870 - val_loss: 4.5245 - val_accuracy: 0.0000e+00\n",
            "Epoch 40/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.5702 - accuracy: 0.0652 - val_loss: 4.4088 - val_accuracy: 0.0000e+00\n",
            "Epoch 41/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 3.6275 - accuracy: 0.0652 - val_loss: 4.3600 - val_accuracy: 0.0000e+00\n",
            "Epoch 42/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.4848 - accuracy: 0.0870 - val_loss: 4.4500 - val_accuracy: 0.0000e+00\n",
            "Epoch 43/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.6086 - accuracy: 0.0652 - val_loss: 4.5330 - val_accuracy: 0.0000e+00\n",
            "Epoch 44/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 3.5178 - accuracy: 0.0870 - val_loss: 4.6356 - val_accuracy: 0.0000e+00\n",
            "Epoch 45/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 3.6975 - accuracy: 0.0000e+00 - val_loss: 4.6890 - val_accuracy: 0.0000e+00\n",
            "Epoch 46/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.4436 - accuracy: 0.0652 - val_loss: 4.7556 - val_accuracy: 0.0000e+00\n",
            "Epoch 47/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.5276 - accuracy: 0.0000e+00 - val_loss: 4.7693 - val_accuracy: 0.0000e+00\n",
            "Epoch 48/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 3.5464 - accuracy: 0.0652 - val_loss: 4.6862 - val_accuracy: 0.0000e+00\n",
            "Epoch 49/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 3.4939 - accuracy: 0.1304 - val_loss: 4.6554 - val_accuracy: 0.0000e+00\n",
            "Epoch 50/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.6341 - accuracy: 0.0000e+00 - val_loss: 4.6041 - val_accuracy: 0.0000e+00\n",
            "Epoch 51/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 3.6042 - accuracy: 0.0652 - val_loss: 4.5557 - val_accuracy: 0.0000e+00\n",
            "Epoch 52/100\n",
            "2/2 [==============================] - 0s 53ms/step - loss: 3.5293 - accuracy: 0.0652 - val_loss: 4.6918 - val_accuracy: 0.0000e+00\n",
            "Epoch 53/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.4209 - accuracy: 0.1522 - val_loss: 5.1198 - val_accuracy: 0.0000e+00\n",
            "Epoch 54/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.4958 - accuracy: 0.0652 - val_loss: 5.4655 - val_accuracy: 0.0000e+00\n",
            "Epoch 55/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.5671 - accuracy: 0.0000e+00 - val_loss: 5.1599 - val_accuracy: 0.0000e+00\n",
            "Epoch 56/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 3.4234 - accuracy: 0.0435 - val_loss: 4.9393 - val_accuracy: 0.0833\n",
            "Epoch 57/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.3609 - accuracy: 0.1739 - val_loss: 5.1004 - val_accuracy: 0.0833\n",
            "Epoch 58/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 3.4175 - accuracy: 0.0870 - val_loss: 5.5420 - val_accuracy: 0.0833\n",
            "Epoch 59/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.3086 - accuracy: 0.1304 - val_loss: 5.8392 - val_accuracy: 0.0833\n",
            "Epoch 60/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 3.2267 - accuracy: 0.2174 - val_loss: 5.9861 - val_accuracy: 0.0833\n",
            "Epoch 61/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.2480 - accuracy: 0.0870 - val_loss: 6.4258 - val_accuracy: 0.0833\n",
            "Epoch 62/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 3.0167 - accuracy: 0.1304 - val_loss: 7.0835 - val_accuracy: 0.0833\n",
            "Epoch 63/100\n",
            "2/2 [==============================] - 0s 47ms/step - loss: 3.0367 - accuracy: 0.1522 - val_loss: 7.1767 - val_accuracy: 0.0833\n",
            "Epoch 64/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 3.2417 - accuracy: 0.0435 - val_loss: 7.1843 - val_accuracy: 0.0833\n",
            "Epoch 65/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 2.7680 - accuracy: 0.2609 - val_loss: 7.9734 - val_accuracy: 0.0833\n",
            "Epoch 66/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 2.6675 - accuracy: 0.2174 - val_loss: 8.5170 - val_accuracy: 0.0833\n",
            "Epoch 67/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 2.5626 - accuracy: 0.2826 - val_loss: 8.9523 - val_accuracy: 0.0833\n",
            "Epoch 68/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 2.4170 - accuracy: 0.3913 - val_loss: 9.6669 - val_accuracy: 0.0833\n",
            "Epoch 69/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 1.8537 - accuracy: 0.4783 - val_loss: 10.1901 - val_accuracy: 0.0833\n",
            "Epoch 70/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 1.5660 - accuracy: 0.5435 - val_loss: 10.4351 - val_accuracy: 0.0833\n",
            "Epoch 71/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 1.7498 - accuracy: 0.5652 - val_loss: 11.4594 - val_accuracy: 0.0833\n",
            "Epoch 72/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 1.5618 - accuracy: 0.5217 - val_loss: 12.2639 - val_accuracy: 0.0833\n",
            "Epoch 73/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 1.6403 - accuracy: 0.5652 - val_loss: 12.6604 - val_accuracy: 0.1667\n",
            "Epoch 74/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 1.2959 - accuracy: 0.6304 - val_loss: 13.1835 - val_accuracy: 0.1667\n",
            "Epoch 75/100\n",
            "2/2 [==============================] - 0s 41ms/step - loss: 1.1108 - accuracy: 0.6739 - val_loss: 14.0326 - val_accuracy: 0.1667\n",
            "Epoch 76/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.9466 - accuracy: 0.6957 - val_loss: 15.0542 - val_accuracy: 0.1667\n",
            "Epoch 77/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.8462 - accuracy: 0.7391 - val_loss: 15.7400 - val_accuracy: 0.1667\n",
            "Epoch 78/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.9018 - accuracy: 0.7609 - val_loss: 16.2038 - val_accuracy: 0.1667\n",
            "Epoch 79/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.6188 - accuracy: 0.7826 - val_loss: 16.2063 - val_accuracy: 0.1667\n",
            "Epoch 80/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.5990 - accuracy: 0.8261 - val_loss: 16.5548 - val_accuracy: 0.1667\n",
            "Epoch 81/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.7828 - accuracy: 0.7609 - val_loss: 16.1883 - val_accuracy: 0.1667\n",
            "Epoch 82/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.8025 - accuracy: 0.7609 - val_loss: 15.7390 - val_accuracy: 0.1667\n",
            "Epoch 83/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.6522 - accuracy: 0.7826 - val_loss: 15.1338 - val_accuracy: 0.1667\n",
            "Epoch 84/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.6841 - accuracy: 0.7826 - val_loss: 14.8333 - val_accuracy: 0.1667\n",
            "Epoch 85/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.4793 - accuracy: 0.8696 - val_loss: 15.8085 - val_accuracy: 0.1667\n",
            "Epoch 86/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.6315 - accuracy: 0.7826 - val_loss: 16.6538 - val_accuracy: 0.1667\n",
            "Epoch 87/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.5298 - accuracy: 0.8478 - val_loss: 16.3290 - val_accuracy: 0.1667\n",
            "Epoch 88/100\n",
            "2/2 [==============================] - 0s 45ms/step - loss: 0.3707 - accuracy: 0.8913 - val_loss: 15.1464 - val_accuracy: 0.1667\n",
            "Epoch 89/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.3912 - accuracy: 0.8478 - val_loss: 13.8665 - val_accuracy: 0.1667\n",
            "Epoch 90/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.6834 - accuracy: 0.7826 - val_loss: 13.1238 - val_accuracy: 0.1667\n",
            "Epoch 91/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.3814 - accuracy: 0.8696 - val_loss: 13.9289 - val_accuracy: 0.1667\n",
            "Epoch 92/100\n",
            "2/2 [==============================] - 0s 46ms/step - loss: 0.3578 - accuracy: 0.9130 - val_loss: 15.7058 - val_accuracy: 0.1667\n",
            "Epoch 93/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.4639 - accuracy: 0.8478 - val_loss: 17.0354 - val_accuracy: 0.1667\n",
            "Epoch 94/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.4650 - accuracy: 0.8913 - val_loss: 17.2692 - val_accuracy: 0.1667\n",
            "Epoch 95/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.4500 - accuracy: 0.8913 - val_loss: 16.7305 - val_accuracy: 0.1667\n",
            "Epoch 96/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.1965 - accuracy: 0.9565 - val_loss: 16.5490 - val_accuracy: 0.1667\n",
            "Epoch 97/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.4331 - accuracy: 0.8478 - val_loss: 16.8871 - val_accuracy: 0.1667\n",
            "Epoch 98/100\n",
            "2/2 [==============================] - 0s 43ms/step - loss: 0.3759 - accuracy: 0.8696 - val_loss: 17.8461 - val_accuracy: 0.1667\n",
            "Epoch 99/100\n",
            "2/2 [==============================] - 0s 44ms/step - loss: 0.2909 - accuracy: 0.9348 - val_loss: 18.9462 - val_accuracy: 0.1667\n",
            "Epoch 100/100\n",
            "2/2 [==============================] - 0s 42ms/step - loss: 0.1394 - accuracy: 0.9783 - val_loss: 20.5953 - val_accuracy: 0.1667\n",
            "Score for fold 10: loss of 15.714924812316895; accuracy of 0.0%\n",
            "------------------------------------------------------------------------\n",
            "Score per fold\n",
            "------------------------------------------------------------------------\n",
            "> Fold 1 - Loss: 14.09227466583252 - Accuracy: 0.0%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 2 - Loss: 9.689757347106934 - Accuracy: 14.28571492433548%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 3 - Loss: 15.010416984558105 - Accuracy: 14.28571492433548%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 4 - Loss: 9.30671501159668 - Accuracy: 14.28571492433548%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 5 - Loss: 5.55063009262085 - Accuracy: 33.33333432674408%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 6 - Loss: 12.899657249450684 - Accuracy: 33.33333432674408%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 7 - Loss: 7.351945877075195 - Accuracy: 16.66666716337204%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 8 - Loss: 7.936411380767822 - Accuracy: 33.33333432674408%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 9 - Loss: 13.110926628112793 - Accuracy: 0.0%\n",
            "------------------------------------------------------------------------\n",
            "> Fold 10 - Loss: 15.714924812316895 - Accuracy: 0.0%\n",
            "------------------------------------------------------------------------\n",
            "Average scores for all folds:\n",
            "> Accuracy: 15.952381491661072 (+- 12.955969768772025)\n",
            "> Loss: 11.066366004943848\n",
            "------------------------------------------------------------------------\n"
          ]
        }
      ],
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout\n",
        "from tensorflow.keras.losses import categorical_crossentropy\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Model configuration\n",
        "batch_size = 32\n",
        "img_width, img_height, img_num_channels = 150, 150, 3\n",
        "no_classes = 55\n",
        "no_epochs = 100\n",
        "optimizer = Adam()\n",
        "verbosity = 1\n",
        "num_folds = 10\n",
        "\n",
        "# Define the paths for the dataset\n",
        "train_path = \"D:/SELF/ML/aksara-detection/code/findingbali/crossvalidation/train\"\n",
        "test_path = \"D:/SELF/ML/aksara-detection/code/findingbali/crossvalidation/test\"\n",
        "\n",
        "# Define the image data generator\n",
        "datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# Load the training dataset\n",
        "train_generator = datagen.flow_from_directory(\n",
        "  train_path,\n",
        "  target_size=(img_width, img_height),\n",
        "  batch_size=batch_size,\n",
        "  class_mode='categorical')\n",
        "\n",
        "# Load the test dataset\n",
        "test_generator = datagen.flow_from_directory(\n",
        "  test_path,\n",
        "  target_size=(img_width, img_height),\n",
        "  batch_size=batch_size,\n",
        "  class_mode='categorical')\n",
        "\n",
        "# Get the input and target data\n",
        "input_train, target_train = train_generator.next()\n",
        "input_test, target_test = test_generator.next()\n",
        "\n",
        "# Determine shape of the data\n",
        "input_shape = (img_width, img_height, img_num_channels)\n",
        "\n",
        "# Normalize data\n",
        "input_train = input_train / 255\n",
        "input_test = input_test / 255\n",
        "\n",
        "# Define per-fold score containers\n",
        "acc_per_fold = []\n",
        "loss_per_fold = []\n",
        "\n",
        "# Merge inputs and targets\n",
        "inputs = np.concatenate((input_train, input_test), axis=0)\n",
        "targets = np.concatenate((target_train, target_test), axis=0)\n",
        "\n",
        "# Define the K-fold Cross Validator\n",
        "kfold = KFold(n_splits=num_folds, shuffle=True)\n",
        "\n",
        "# K-fold Cross Validation model evaluation\n",
        "fold_no = 1\n",
        "for train, test in kfold.split(inputs, targets):\n",
        "\n",
        "  # Define the model architecture\n",
        "  model = Sequential()\n",
        "  model.add(Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=input_shape))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
        "  model.add(MaxPooling2D(pool_size=(2, 2)))\n",
        "  model.add(Flatten())\n",
        "  model.add(Dense(256, activation='relu'))\n",
        "  model.add(Dropout(0.7))  # Increase dropout rate\n",
        "  model.add(Dense(no_classes, activation='softmax'))\n",
        "\n",
        "\n",
        "  # Compile the model\n",
        "  model.compile(loss=categorical_crossentropy,\n",
        "                optimizer=Adam(learning_rate=0.001),\n",
        "                metrics=['accuracy'])\n",
        "\n",
        "  # Generate a print\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'Training for fold {fold_no} ...')\n",
        "\n",
        "  # Split the training data into training and validation sets\n",
        "  val_split = 0.2\n",
        "  train_indices = int(len(train) * (1 - val_split))\n",
        "  train_data = inputs[train[:train_indices]]\n",
        "  train_targets = targets[train[:train_indices]]\n",
        "  val_data = inputs[train[train_indices:]]\n",
        "  val_targets = targets[train[train_indices:]]\n",
        "\n",
        "  # Fit data to model with validation data\n",
        "  history = model.fit(train_data, train_targets,\n",
        "                      validation_data=(val_data, val_targets),\n",
        "                      batch_size=batch_size,\n",
        "                      epochs=no_epochs,\n",
        "                      verbose=verbosity)\n",
        "\n",
        "  # Generate generalization metrics\n",
        "  scores = model.evaluate(inputs[test], targets[test], verbose=0)\n",
        "  print(f'Score for fold {fold_no}: {model.metrics_names[0]} of {scores[0]}; {model.metrics_names[1]} of {scores[1]*100}%')\n",
        "  acc_per_fold.append(scores[1] * 100)\n",
        "  loss_per_fold.append(scores[0])\n",
        "\n",
        "  # Increase fold number\n",
        "  fold_no = fold_no + 1\n",
        "\n",
        "# == Provide average scores ==\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Score per fold')\n",
        "for i in range(0, len(acc_per_fold)):\n",
        "  print('------------------------------------------------------------------------')\n",
        "  print(f'> Fold {i+1} - Loss: {loss_per_fold[i]} - Accuracy: {acc_per_fold[i]}%')\n",
        "print('------------------------------------------------------------------------')\n",
        "print('Average scores for all folds:')\n",
        "print(f'> Accuracy: {np.mean(acc_per_fold)} (+- {np.std(acc_per_fold)})')\n",
        "print(f'> Loss: {np.mean(loss_per_fold)}')\n",
        "print('------------------------------------------------------------------------')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Define the path to save the model\n",
        "model_path = \"D:/SELF/ML/aksara-detection/code/findingbali/model/modelcross.h5\"\n",
        "\n",
        "# Save the model\n",
        "model.save(model_path)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 1200x400 with 2 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load the model from the file\n",
        "model = tf.keras.models.load_model(\"D:/SELF/ML/aksara-detection/code/findingbali/model/modelcross.h5\")\n",
        "\n",
        "# Assume history is the returned object from model.fit()\n",
        "\n",
        "# Plot training & validation accuracy values\n",
        "plt.figure(figsize=(12, 4))\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])  # Add this line to plot validation accuracy\n",
        "plt.title('Model accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')  # Update legend labels\n",
        "\n",
        "# Plot training & validation loss values\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])  # Add this line to plot validation loss\n",
        "plt.title('Model loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper left')  # Update legend labels\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.preprocessing import image\n",
        "import numpy as np\n",
        "\n",
        "# Load the trained model\n",
        "model = tf.keras.models.load_model(\"D:/SELF/ML/aksara-detection/code/findingbali/model/modelcross.h5\")\n",
        "\n",
        "# Function to classify the input image\n",
        "def classify_image(image_path):\n",
        "    img = image.load_img(image_path, target_size=(150, 150))\n",
        "    img_array = image.img_to_array(img)\n",
        "    img_array = np.expand_dims(img_array, axis=0)\n",
        "    img_array /= 255.0\n",
        "\n",
        "    prediction = model.predict(img_array)\n",
        "    class_index = np.argmax(prediction)\n",
        "    confidence = prediction[0][class_index]\n",
        "\n",
        "    return class_index, confidence\n",
        "\n",
        "# Update the labels dictionary with class mappings\n",
        "labels = {\n",
        "    0: 'Adeg-Adeg',\n",
        "    1: 'Ba',\n",
        "    2: 'Bisah',\n",
        "    3: 'Ca',\n",
        "    4: 'Cecek',\n",
        "    5: 'Da',\n",
        "    6: 'Delapan',\n",
        "    7: 'Dua',\n",
        "    8: 'Empat',\n",
        "    9: 'Enam',\n",
        "    10: 'Ga',\n",
        "    11: 'Gantungan Ba',\n",
        "    12: 'Gantungan Ca',\n",
        "    13: 'Gantungan Da',\n",
        "    14: 'Gantungan Ga',\n",
        "    15: 'Gantungan Ha',\n",
        "    16: 'Gantungan Ja',\n",
        "    17: 'Gantungan Ka',\n",
        "    18: 'Gantungan La',\n",
        "    19: 'Gantungan Ma',\n",
        "    20: 'Gantungan Na',\n",
        "    21: 'Gantungan Nga',\n",
        "    22: 'Gantungan Nya',\n",
        "    23: 'Gantungan Pa',\n",
        "    24: 'Gantungan Ra',\n",
        "    25: 'Gantungan Sa',\n",
        "    26: 'Gantungan Ta',\n",
        "    27: 'Gantungan Wa',\n",
        "    28: 'Gantungan Ya',\n",
        "    29: 'Ha',\n",
        "    30: 'Ja',\n",
        "    31: 'Ka',\n",
        "    32: 'La',\n",
        "    33: 'Lima',\n",
        "    34: 'Ma',\n",
        "    35: 'Na',\n",
        "    36: 'Nga',\n",
        "    37: 'Nya',\n",
        "    38: 'Pa',\n",
        "    39: 'Pepet',\n",
        "    40: 'Ra',\n",
        "    41: 'Sa',\n",
        "    42: 'Satu',\n",
        "    43: 'Sembilan',\n",
        "    44: 'Suku',\n",
        "    45: 'Surang',\n",
        "    46: 'Ta',\n",
        "    47: 'Taleng',\n",
        "    48: 'Taleng Tedong',\n",
        "    49: 'Tedong',\n",
        "    50: 'Tiga',\n",
        "    51: 'Tujuh',\n",
        "    52: 'Ulu',\n",
        "    53: 'Wa',\n",
        "    54: 'Ya'\n",
        "}\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Checking Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 432ms/step\n",
            "The photo belongs to class 'Satu' with confidence 1.00\n"
          ]
        }
      ],
      "source": [
        "# Choose a photo and classify it\n",
        "photo_path = \"D:/SELF/ML/aksara-detection/code/findingbali/testing/Cecek.jpg\"\n",
        "class_index, confidence = classify_image(photo_path)\n",
        "\n",
        "# Get the label for the predicted class\n",
        "predicted_class = labels[class_index]\n",
        "\n",
        "print(f\"The photo belongs to class '{predicted_class}' with confidence {confidence:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 17ms/step\n",
            "The photo belongs to class 'Satu' with confidence 1.00\n"
          ]
        }
      ],
      "source": [
        "# Choose a photo and classify it\n",
        "photo_path = \"D:/SELF/ML/aksara-detection/code/findingbali/testing/Da.jpg\"\n",
        "class_index, confidence = classify_image(photo_path)\n",
        "\n",
        "# Get the label for the predicted class\n",
        "predicted_class = labels[class_index]\n",
        "\n",
        "print(f\"The photo belongs to class '{predicted_class}' with confidence {confidence:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 16ms/step\n",
            "The photo belongs to class 'Na' with confidence 1.00\n"
          ]
        }
      ],
      "source": [
        "# Choose a photo and classify it\n",
        "photo_path = \"D:/SELF/ML/aksara-detection/code/findingbali/testing/Enam.jpg\"\n",
        "class_index, confidence = classify_image(photo_path)\n",
        "\n",
        "# Get the label for the predicted class\n",
        "predicted_class = labels[class_index]\n",
        "\n",
        "print(f\"The photo belongs to class '{predicted_class}' with confidence {confidence:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 16ms/step\n",
            "The photo belongs to class 'Gantungan Ka' with confidence 0.79\n"
          ]
        }
      ],
      "source": [
        "# Choose a photo and classify it\n",
        "photo_path = \"D:/SELF/ML/aksara-detection/code/findingbali/testing/Gantungan Ka.jpg\"\n",
        "class_index, confidence = classify_image(photo_path)\n",
        "\n",
        "# Get the label for the predicted class\n",
        "predicted_class = labels[class_index]\n",
        "\n",
        "print(f\"The photo belongs to class '{predicted_class}' with confidence {confidence:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 18ms/step\n",
            "The photo belongs to class 'Na' with confidence 0.44\n"
          ]
        }
      ],
      "source": [
        "# Choose a photo and classify it\n",
        "photo_path = \"D:/SELF/ML/aksara-detection/code/findingbali/testing/Gantungan Ta.jpg\"\n",
        "class_index, confidence = classify_image(photo_path)\n",
        "\n",
        "# Get the label for the predicted class\n",
        "predicted_class = labels[class_index]\n",
        "\n",
        "print(f\"The photo belongs to class '{predicted_class}' with confidence {confidence:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 17ms/step\n",
            "The photo belongs to class 'Gantungan Ya' with confidence 0.93\n"
          ]
        }
      ],
      "source": [
        "# Choose a photo and classify it\n",
        "photo_path = \"D:/SELF/ML/aksara-detection/code/findingbali/testing/Gantungan Ya.jpg\"\n",
        "class_index, confidence = classify_image(photo_path)\n",
        "\n",
        "# Get the label for the predicted class\n",
        "predicted_class = labels[class_index]\n",
        "\n",
        "print(f\"The photo belongs to class '{predicted_class}' with confidence {confidence:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 18ms/step\n",
            "The photo belongs to class 'Ka' with confidence 1.00\n"
          ]
        }
      ],
      "source": [
        "# Choose a photo and classify it\n",
        "photo_path = \"D:/SELF/ML/aksara-detection/code/findingbali/testing/Ka.jpg\"\n",
        "class_index, confidence = classify_image(photo_path)\n",
        "\n",
        "# Get the label for the predicted class\n",
        "predicted_class = labels[class_index]\n",
        "\n",
        "print(f\"The photo belongs to class '{predicted_class}' with confidence {confidence:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 15ms/step\n",
            "The photo belongs to class 'Satu' with confidence 0.69\n"
          ]
        }
      ],
      "source": [
        "# Choose a photo and classify it\n",
        "photo_path = \"D:/SELF/ML/aksara-detection/code/findingbali/testing/Ma.jpg\"\n",
        "class_index, confidence = classify_image(photo_path)\n",
        "\n",
        "# Get the label for the predicted class\n",
        "predicted_class = labels[class_index]\n",
        "\n",
        "print(f\"The photo belongs to class '{predicted_class}' with confidence {confidence:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 17ms/step\n",
            "The photo belongs to class 'Ka' with confidence 0.95\n"
          ]
        }
      ],
      "source": [
        "# Choose a photo and classify it\n",
        "photo_path = \"D:/SELF/ML/aksara-detection/code/findingbali/testing/Na.jpg\"\n",
        "class_index, confidence = classify_image(photo_path)\n",
        "\n",
        "# Get the label for the predicted class\n",
        "predicted_class = labels[class_index]\n",
        "\n",
        "print(f\"The photo belongs to class '{predicted_class}' with confidence {confidence:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 17ms/step\n",
            "The photo belongs to class 'Pepet' with confidence 0.98\n"
          ]
        }
      ],
      "source": [
        "# Choose a photo and classify it\n",
        "photo_path = \"D:/SELF/ML/aksara-detection/code/findingbali/testing/Pepet.jpg\"\n",
        "class_index, confidence = classify_image(photo_path)\n",
        "\n",
        "# Get the label for the predicted class\n",
        "predicted_class = labels[class_index]\n",
        "\n",
        "print(f\"The photo belongs to class '{predicted_class}' with confidence {confidence:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 17ms/step\n",
            "The photo belongs to class 'Suku' with confidence 0.99\n"
          ]
        }
      ],
      "source": [
        "# Choose a photo and classify it\n",
        "photo_path = \"D:/SELF/ML/aksara-detection/code/findingbali/testing/Suku.jpg\"\n",
        "class_index, confidence = classify_image(photo_path)\n",
        "\n",
        "# Get the label for the predicted class\n",
        "predicted_class = labels[class_index]\n",
        "\n",
        "print(f\"The photo belongs to class '{predicted_class}' with confidence {confidence:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 15ms/step\n",
            "The photo belongs to class 'Ta' with confidence 0.63\n"
          ]
        }
      ],
      "source": [
        "# Choose a photo and classify it\n",
        "photo_path = \"D:/SELF/ML/aksara-detection/code/findingbali/testing/Ta.jpg\"\n",
        "class_index, confidence = classify_image(photo_path)\n",
        "\n",
        "# Get the label for the predicted class\n",
        "predicted_class = labels[class_index]\n",
        "\n",
        "print(f\"The photo belongs to class '{predicted_class}' with confidence {confidence:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 20ms/step\n",
            "The photo belongs to class 'Ulu' with confidence 0.69\n"
          ]
        }
      ],
      "source": [
        "# Choose a photo and classify it\n",
        "photo_path = \"D:/SELF/ML/aksara-detection/code/findingbali/testing/Ulu.jpg\"\n",
        "class_index, confidence = classify_image(photo_path)\n",
        "\n",
        "# Get the label for the predicted class\n",
        "predicted_class = labels[class_index]\n",
        "\n",
        "print(f\"The photo belongs to class '{predicted_class}' with confidence {confidence:.2f}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1/1 [==============================] - 0s 17ms/step\n",
            "The photo belongs to class 'Ya' with confidence 0.97\n"
          ]
        }
      ],
      "source": [
        "# Choose a photo and classify it\n",
        "photo_path = \"D:/SELF/ML/aksara-detection/code/findingbali/testing/Ya.jpg\"\n",
        "class_index, confidence = classify_image(photo_path)\n",
        "\n",
        "# Get the label for the predicted class\n",
        "predicted_class = labels[class_index]\n",
        "\n",
        "print(f\"The photo belongs to class '{predicted_class}' with confidence {confidence:.2f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Saving Models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {
        "id": "wKM8vrpjt0iC"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 3 of 3). These functions will not be directly callable after loading.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: D:/SELF/ML/aksara-detection/code/findingbali/hasil/aksarabali5.json\\assets\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:tensorflow:Assets written to: D:/SELF/ML/aksara-detection/code/findingbali/hasil/aksarabali5.json\\assets\n"
          ]
        }
      ],
      "source": [
        "model_json = model.to_json()\n",
        "with open(\"aksarabali5.json\", \"w\") as json_file:\n",
        "    json_file.write(model_json)\n",
        "\n",
        "model.save(\"D:/SELF/ML/aksara-detection/code/findingbali/hasil/aksarabali5.json\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.18"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
